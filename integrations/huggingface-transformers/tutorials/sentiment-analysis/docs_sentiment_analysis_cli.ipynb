{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "566293ac880847c881b31156a3e23058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad6f71025b641e2b3fb2d09828a599f",
              "IPY_MODEL_fb018ff11e5a4cedb2c24a530dc35051",
              "IPY_MODEL_b02c170e03a141739d9a5829a198a0fd"
            ],
            "layout": "IPY_MODEL_0fe3690ffec348648cd9f117fa5c3210"
          }
        },
        "9ad6f71025b641e2b3fb2d09828a599f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ba58f4af1c448c893a505bb9d49dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_9c4f62cfcc0b40548aba00fb89db60c1",
            "value": "Downloading: "
          }
        },
        "fb018ff11e5a4cedb2c24a530dc35051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afded944c3e04103b23f7c00f71ed3ea",
            "max": 1887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c9d7e2e19094655bfbf9ff883b95d5c",
            "value": 1887
          }
        },
        "b02c170e03a141739d9a5829a198a0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3be6cc4d76804eedb7f083ab25954b93",
            "placeholder": "​",
            "style": "IPY_MODEL_8d506e4db2ef432bb2a8cd52b002c374",
            "value": " 5.03k/? [00:00&lt;00:00, 209kB/s]"
          }
        },
        "0fe3690ffec348648cd9f117fa5c3210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ba58f4af1c448c893a505bb9d49dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4f62cfcc0b40548aba00fb89db60c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afded944c3e04103b23f7c00f71ed3ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9d7e2e19094655bfbf9ff883b95d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3be6cc4d76804eedb7f083ab25954b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d506e4db2ef432bb2a8cd52b002c374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "476cb165e0e4498f844a5de0c18ee260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e046ccabb9f5456cbd13bdbb8351906d",
              "IPY_MODEL_d8903ec810be4cfa933101b1de8d63a5",
              "IPY_MODEL_1f62b91c48e2479aac69c6dbe658d3f6"
            ],
            "layout": "IPY_MODEL_d8a47aabb4734fc28867ab20d9cde6fb"
          }
        },
        "e046ccabb9f5456cbd13bdbb8351906d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283c1e3d22ab4bc6815183334c01969c",
            "placeholder": "​",
            "style": "IPY_MODEL_c9595d6efa2a4241bae1e4f4847e12f2",
            "value": "Downloading: "
          }
        },
        "d8903ec810be4cfa933101b1de8d63a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5313565f964b59a379dccaa5ec6e65",
            "max": 921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e879a1b65e4f48fea29e0daac81584b8",
            "value": 921
          }
        },
        "1f62b91c48e2479aac69c6dbe658d3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae024ecf2a34a54baac6de933ef98bd",
            "placeholder": "​",
            "style": "IPY_MODEL_ab066ac13ae149f5ac184296afbfb99d",
            "value": " 2.02k/? [00:00&lt;00:00, 113kB/s]"
          }
        },
        "d8a47aabb4734fc28867ab20d9cde6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283c1e3d22ab4bc6815183334c01969c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9595d6efa2a4241bae1e4f4847e12f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d5313565f964b59a379dccaa5ec6e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e879a1b65e4f48fea29e0daac81584b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dae024ecf2a34a54baac6de933ef98bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab066ac13ae149f5ac184296afbfb99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c8b25265bd4df9b58a4cb034017d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b802a594e02c40bfa7defa75da263cf1",
              "IPY_MODEL_211113ed758348f2a3ea84a0eeb42556",
              "IPY_MODEL_668611a1b4124579a0d19e412525b6fb"
            ],
            "layout": "IPY_MODEL_1adb4b370f434a67afe28a0e5a17e68c"
          }
        },
        "b802a594e02c40bfa7defa75da263cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50676f380e64591a908375083267a24",
            "placeholder": "​",
            "style": "IPY_MODEL_613db94f4de44b4fb9997b8447ff562e",
            "value": "Downloading: 100%"
          }
        },
        "211113ed758348f2a3ea84a0eeb42556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfba9ab7c49d478dac3c693c186df0cd",
            "max": 487770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca3576bdd4424528bc8d9c0ea9b19b3c",
            "value": 487770
          }
        },
        "668611a1b4124579a0d19e412525b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8551aee7bb4413bb5bbad8cb52a5286",
            "placeholder": "​",
            "style": "IPY_MODEL_4bb09069a695422cb8acd7dcc74b94c4",
            "value": " 488k/488k [00:01&lt;00:00, 631kB/s]"
          }
        },
        "1adb4b370f434a67afe28a0e5a17e68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50676f380e64591a908375083267a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613db94f4de44b4fb9997b8447ff562e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfba9ab7c49d478dac3c693c186df0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3576bdd4424528bc8d9c0ea9b19b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8551aee7bb4413bb5bbad8cb52a5286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb09069a695422cb8acd7dcc74b94c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5426133a767b49558aadf8031acce26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49c6fb16291146568b8280a4e6cf656e",
              "IPY_MODEL_46d0818f4e924c368d768490da969f38",
              "IPY_MODEL_f732e5ae996844cb9a9bf7045bec6baa"
            ],
            "layout": "IPY_MODEL_f9d4bf2a0de34ca6b25fdb42be79aad9"
          }
        },
        "49c6fb16291146568b8280a4e6cf656e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf72d02194344d42b26ee334380c33a2",
            "placeholder": "​",
            "style": "IPY_MODEL_997d916785df424382e9b0b3a16a0937",
            "value": ""
          }
        },
        "46d0818f4e924c368d768490da969f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04346244975e4f5e9009deb3562246ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3ed829b7374b2bbe0e3a87d5ecdb87",
            "value": 1
          }
        },
        "f732e5ae996844cb9a9bf7045bec6baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4401fb79a9a4b3bb597226da22fc0e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6a30cb870be941169aaaf3217faaa70a",
            "value": " 7639/0 [00:00&lt;00:00, 15745.03 examples/s]"
          }
        },
        "f9d4bf2a0de34ca6b25fdb42be79aad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bf72d02194344d42b26ee334380c33a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "997d916785df424382e9b0b3a16a0937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04346244975e4f5e9009deb3562246ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6e3ed829b7374b2bbe0e3a87d5ecdb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4401fb79a9a4b3bb597226da22fc0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a30cb870be941169aaaf3217faaa70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d56ce514bc5649c398a6d81a6bafb0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7db6ca3a6c2e4bccb65a2eebff5412ef",
              "IPY_MODEL_42de41b7b4e443f399add54a0fdb7403",
              "IPY_MODEL_4d58cd5c68d6432091719b734c4cdc2c"
            ],
            "layout": "IPY_MODEL_e30c9080e3d24f27a2a108d0f36adb9e"
          }
        },
        "7db6ca3a6c2e4bccb65a2eebff5412ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51aaed1f169147cca061d9fcca9ed8a0",
            "placeholder": "​",
            "style": "IPY_MODEL_4417b06b81f94cd19d718b3e306602be",
            "value": ""
          }
        },
        "42de41b7b4e443f399add54a0fdb7403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ac381d438e4686bc14aa636bc83cdf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28c7b41b06bf4520a6b57ffdb6cf7f4b",
            "value": 1
          }
        },
        "4d58cd5c68d6432091719b734c4cdc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab76c15a18d647c9b68ebf71e32c19c1",
            "placeholder": "​",
            "style": "IPY_MODEL_a33cd277de2c4fa5ba82e7258073b361",
            "value": " 476/0 [00:00&lt;00:00, 4758.90 examples/s]"
          }
        },
        "e30c9080e3d24f27a2a108d0f36adb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "51aaed1f169147cca061d9fcca9ed8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4417b06b81f94cd19d718b3e306602be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72ac381d438e4686bc14aa636bc83cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "28c7b41b06bf4520a6b57ffdb6cf7f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab76c15a18d647c9b68ebf71e32c19c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33cd277de2c4fa5ba82e7258073b361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5734587799344996b0f84002f36e97b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2becc1379694010922ec61d24740de5",
              "IPY_MODEL_233d5c00e05b4fb3bac275a60ed1dd75",
              "IPY_MODEL_c77e529607364c07bb9466470ddb757b"
            ],
            "layout": "IPY_MODEL_fe75483260134b60bfd5e2083409748c"
          }
        },
        "f2becc1379694010922ec61d24740de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cde3ab5088a408d8ee44fc2b66b1dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_03be1f136fbb4848b9eeb70b6d79e46d",
            "value": ""
          }
        },
        "233d5c00e05b4fb3bac275a60ed1dd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc00d27cc7641528b171fa8d69bf0d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92633305bf00461cae9f9ca3757d626d",
            "value": 1
          }
        },
        "c77e529607364c07bb9466470ddb757b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76708c01aa94a56bcc03ac8b8f5d149",
            "placeholder": "​",
            "style": "IPY_MODEL_a675ba9b703a4cf39afb1da981abf89b",
            "value": " 137/0 [00:00&lt;00:00, 1369.74 examples/s]"
          }
        },
        "fe75483260134b60bfd5e2083409748c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3cde3ab5088a408d8ee44fc2b66b1dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03be1f136fbb4848b9eeb70b6d79e46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc00d27cc7641528b171fa8d69bf0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "92633305bf00461cae9f9ca3757d626d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d76708c01aa94a56bcc03ac8b8f5d149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a675ba9b703a4cf39afb1da981abf89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e6c845dcc24aad991e35d1931aff5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f581feff3951424abd982d26eeb987a8",
              "IPY_MODEL_3c6d873f7a7d46d39751febc963dd8e8",
              "IPY_MODEL_4de5e9ec702a43e391c2bffec8c57d08"
            ],
            "layout": "IPY_MODEL_cdedb9db9b274b8a9dcc705c4c01ef72"
          }
        },
        "f581feff3951424abd982d26eeb987a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213c5b0c334d45608e6688dc400b24ec",
            "placeholder": "​",
            "style": "IPY_MODEL_9db54ccf8be242ff86566c13b88cb98b",
            "value": "100%"
          }
        },
        "3c6d873f7a7d46d39751febc963dd8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d2f71c08fe4c39b02bbc357970dbdc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d91fe0dde842aa9e5b5be803ab0d95",
            "value": 3
          }
        },
        "4de5e9ec702a43e391c2bffec8c57d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c7f47fb840435b8cf833d2ca2c65b0",
            "placeholder": "​",
            "style": "IPY_MODEL_508f4cdd142a4958bc6abcf58926b59d",
            "value": " 3/3 [00:00&lt;00:00, 48.55it/s]"
          }
        },
        "cdedb9db9b274b8a9dcc705c4c01ef72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213c5b0c334d45608e6688dc400b24ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db54ccf8be242ff86566c13b88cb98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d2f71c08fe4c39b02bbc357970dbdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d91fe0dde842aa9e5b5be803ab0d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45c7f47fb840435b8cf833d2ca2c65b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508f4cdd142a4958bc6abcf58926b59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115c1fe4c88e49f8a5f7a9b08e756a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ca501ae02d74e4ea9fc2bba9a67c673",
              "IPY_MODEL_9d8e7c853bf144eaba44000f60b5c175",
              "IPY_MODEL_441568c8a77d4574bca4b570e5967293"
            ],
            "layout": "IPY_MODEL_4458b488ab794c0b9b52d90b3028f627"
          }
        },
        "2ca501ae02d74e4ea9fc2bba9a67c673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ac3f6d80de4be2a6bf92da4222b51f",
            "placeholder": "​",
            "style": "IPY_MODEL_79b4deed99b6446994180b85d6bdf1cf",
            "value": "100%"
          }
        },
        "9d8e7c853bf144eaba44000f60b5c175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1d8a4b4e024ee684032b7109e7d967",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98233e3f890c4be7bff265b1dfdd7abf",
            "value": 3
          }
        },
        "441568c8a77d4574bca4b570e5967293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3626b2df8aac4feea331442f712c7f70",
            "placeholder": "​",
            "style": "IPY_MODEL_315cb39123814033859d576caafbfcdf",
            "value": " 3/3 [00:00&lt;00:00, 121.10it/s]"
          }
        },
        "4458b488ab794c0b9b52d90b3028f627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ac3f6d80de4be2a6bf92da4222b51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b4deed99b6446994180b85d6bdf1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b1d8a4b4e024ee684032b7109e7d967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98233e3f890c4be7bff265b1dfdd7abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3626b2df8aac4feea331442f712c7f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315cb39123814033859d576caafbfcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "197363819ce94edd988f026e56a67326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eed2def147540de8135ceb93c077952",
              "IPY_MODEL_f0c4ab1249e24040a3e87d2ef08a3a2f",
              "IPY_MODEL_6f0eed9f129f47ce9d5196a392e54f27"
            ],
            "layout": "IPY_MODEL_f64e467c48aa4314b8cd9b256c58f3ba"
          }
        },
        "4eed2def147540de8135ceb93c077952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8811b76169b48cea328354b1952d9aa",
            "placeholder": "​",
            "style": "IPY_MODEL_b662d86d9e894d7c83550894d88c2f17",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "f0c4ab1249e24040a3e87d2ef08a3a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241496d6391b4242ab90490d5a9d2e9b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba411ee74b504aa991e0ddb2bd421728",
            "value": 1
          }
        },
        "6f0eed9f129f47ce9d5196a392e54f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16723d41863f4433bdf436d8e34ac3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_4285c3c49dbb404b82865fe700de22ee",
            "value": " 1/1 [00:00&lt;00:00, 14.36ba/s]"
          }
        },
        "f64e467c48aa4314b8cd9b256c58f3ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8811b76169b48cea328354b1952d9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b662d86d9e894d7c83550894d88c2f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "241496d6391b4242ab90490d5a9d2e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba411ee74b504aa991e0ddb2bd421728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16723d41863f4433bdf436d8e34ac3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4285c3c49dbb404b82865fe700de22ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dde9c154d1b4a3a9609bb741ee8be5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fbd0c17e02941c1878896e250b4aa80",
              "IPY_MODEL_6375ddde788140ab9b30e50b7396ad7a",
              "IPY_MODEL_51a1e28ea0db4555b73376578b16e5d4"
            ],
            "layout": "IPY_MODEL_a6adf99498f44730bc89ab2fdff65716"
          }
        },
        "1fbd0c17e02941c1878896e250b4aa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c9b12a90be4da6b2284754561c5105",
            "placeholder": "​",
            "style": "IPY_MODEL_98903170d7b944158860b9acf7ee82a3",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "6375ddde788140ab9b30e50b7396ad7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f27b78522e494462a4a7ac95f6701af9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9bb8144b5b74ffcb9eb03330e215f67",
            "value": 1
          }
        },
        "51a1e28ea0db4555b73376578b16e5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d33ba66e2ef4e1a93fb9576aa68d38b",
            "placeholder": "​",
            "style": "IPY_MODEL_30dcae33cc2e41dc8194f5787de1991b",
            "value": " 1/1 [00:00&lt;00:00, 31.66ba/s]"
          }
        },
        "a6adf99498f44730bc89ab2fdff65716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c9b12a90be4da6b2284754561c5105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98903170d7b944158860b9acf7ee82a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f27b78522e494462a4a7ac95f6701af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bb8144b5b74ffcb9eb03330e215f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d33ba66e2ef4e1a93fb9576aa68d38b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dcae33cc2e41dc8194f5787de1991b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis: Sparse Transfer Learning with the CLI**\n",
        "\n",
        "In this example, you will fine-tune a 90% pruned BERT model onto some sentiment-analysis datasets using SparseML's CLI.\n",
        "\n",
        "### **Sparse Transfer Learning Overview**\n",
        "\n",
        "Sparse Transfer Learning is very similiar to typical fine-tuning you are used to when training models. However, with Sparse Transfer Learning, we start the training process from a pre-sparsified checkpoint and maintain the sparsity structure while the fine tuning occurs. At the end, you will have a sparse model trained on your dataset, ready to be deployed with DeepSparse for GPU-class performance on CPUs!\n",
        "\n",
        "### **Pre-Sparsified BERT**\n",
        "SparseZoo, Neural Magic's open source repository of pre-sparsified models, contains a 90% pruned version of BERT, which has been sparsified on the upstream Wikipedia and BookCorpus datasets with the\n",
        "masked language modeling objective. [Check out the model card](https://sparsezoo.neuralmagic.com/models/nlp%2Fmasked_language_modeling%2Fobert-base%2Fpytorch%2Fhuggingface%2Fwikipedia_bookcorpus%2Fpruned90-none). We will use this model as the starting point for the transfer learning process.\n",
        "\n",
        "\n",
        "***Let's dive in!***"
      ],
      "metadata": {
        "id": "kSNEB-3orJ9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installation**\n",
        "\n",
        "Install SparseML via `pip`.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0WybTbssU0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nr5jM2zoqzuG",
        "outputId": "cc7186e7-288e-49b8-b57c-e04f98215b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.13.1+cu116\n",
            "Uninstalling torch-1.13.1+cu116:\n",
            "  Successfully uninstalled torch-1.13.1+cu116\n",
            "Found existing installation: torchvision 0.14.1+cu116\n",
            "Uninstalling torchvision-0.14.1+cu116:\n",
            "  Successfully uninstalled torchvision-0.14.1+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sparseml[torch]\n",
            "  Downloading sparseml-1.4.0-py3-none-any.whl (904 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.8/904.8 KB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toposort>=1.0\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Collecting GPUtil>=1.4.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (0.18.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (23.0)\n",
            "Requirement already satisfied: setuptools<=59.5.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (57.4.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (7.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (1.0.2)\n",
            "Collecting click~=8.0.0\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter>=1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (5.4.8)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (4.64.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (3.19.6)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (1.3.5)\n",
            "Collecting onnx<=1.12.0,>=1.5.0\n",
            "  Downloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (1.7.3)\n",
            "Collecting merge-args>=0.1.0\n",
            "  Downloading merge_args-0.1.5-py2.py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (2.25.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (3.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (6.0)\n",
            "Requirement already satisfied: progressbar2>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (3.38.0)\n",
            "Requirement already satisfied: pydantic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from sparseml[torch]) (1.10.5)\n",
            "Collecting numpy<=1.21.6,>=1.0.0\n",
            "  Downloading numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sparsezoo~=1.4.0\n",
            "  Downloading sparsezoo-1.4.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gputils\n",
            "  Downloading gputils-1.0.6-py3-none-any.whl (3.8 kB)\n",
            "Collecting torch<=1.12.1,>=1.1.0\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (5.3.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (3.0.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.0.0->sparseml[torch]) (3.6.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->sparseml[torch]) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->sparseml[torch]) (6.3.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->sparseml[torch]) (6.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->sparseml[torch]) (4.38.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx<=1.12.0,>=1.5.0->sparseml[torch]) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.0->sparseml[torch]) (2022.7.1)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from progressbar2>=3.0.0->sparseml[torch]) (3.5.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from progressbar2>=3.0.0->sparseml[torch]) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sparseml[torch]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sparseml[torch]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sparseml[torch]) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sparseml[torch]) (4.0.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.15.0->sparseml[torch]) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.15.0->sparseml[torch]) (2023.2.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.15.0->sparseml[torch]) (3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.15.0->sparseml[torch]) (2.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->sparseml[torch]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->sparseml[torch]) (1.2.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torch]) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torch]) (6.1.12)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (4.4.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (21.3.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (5.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (2.11.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (0.16.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->sparseml[torch]) (5.7.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (6.0.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->sparseml[torch]) (1.5.0)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook->jupyter>=1.0.0->sparseml[torch]) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0.0->sparseml[torch]) (3.0.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (2.16.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->sparseml[torch]) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->sparseml[torch]) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torch]) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->sparseml[torch]) (0.5.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torch]) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torch]) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook->jupyter>=1.0.0->sparseml[torch]) (3.14.0)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=22bcd110d9f91fc61f84901f04a5f980b3eeeff252101e6410fa8ec84a73072b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/03/bb/7a97840eb54479b328672e15a536e49dc60da200fb21564d53\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: toposort, merge-args, GPUtil, torch, qtpy, numpy, jedi, click, onnx, sparsezoo, gputils, qtconsole, jupyter, sparseml\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.11 requires torchvision>=0.8.2, which is not installed.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GPUtil-1.4.0 click-8.0.4 gputils-1.0.6 jedi-0.18.2 jupyter-1.0.0 merge-args-0.1.5 numpy-1.21.6 onnx-1.12.0 qtconsole-5.4.0 qtpy-2.3.0 sparseml-1.4.0 sparsezoo-1.4.0 toposort-1.10 torch-1.12.1\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall torch torchvision -y\n",
        "%pip install sparseml[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are running on Google Colab, restart the runtime after this step."
      ],
      "metadata": {
        "id": "1SlYUvD61ppy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.transformers.text_classification --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BT_fq1tk2O4Q",
        "outputId": "5136612a-3128-45c4-9980-0bedd9a227f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-27 03:10:00 sparseml.transformers WARNING  sparseml-transformers v4.23.1 installation not detected. Installing  sparseml-transformers v4.23.1 dependencies if transformers is already  installed in the environment, it will be overwritten. Set  environment variable NM_NO_AUTOINSTALL_TRANSFORMERS to disable\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.23.1\n",
            "  Downloading https://github.com/neuralmagic/transformers/releases/download/v1.4/transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets<=1.18.4\n",
            "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.23.1) (1.21.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets<=1.18.4) (3.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets<=1.18.4) (1.3.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets<=1.18.4) (9.0.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets<=1.18.4) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets<=1.18.4) (2023.1.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<=1.18.4) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.23.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.23.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.23.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.23.1) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets<=1.18.4) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets<=1.18.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets<=1.18.4) (1.15.0)\n",
            "Building wheels for collected packages: sklearn, seqeval\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=3dca32a425e0e2613c0769f32a9d926f966d1128b64f9b0de264ff61976209aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=d5a31a797765c2c4a0cc9840ada7f8e988c397a9ea6c1a14b2689cd09b247920\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built sklearn seqeval\n",
            "Installing collected packages: tokenizers, sklearn, xxhash, urllib3, multiprocess, seqeval, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.11 requires torchvision>=0.8.2, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-1.18.4 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 seqeval-1.2.2 sklearn-0.0.post1 tokenizers-0.13.2 transformers-4.23.1 urllib3-1.26.14 xxhash-3.2.0\n",
            "2023-02-27 03:10:27 sparseml.transformers INFO     sparseml-transformers and dependencies successfully installed\n",
            "2023-02-27 03:10:28.488524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-27 03:10:31.512366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 03:10:31.512829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 03:10:31.512858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "usage: sparseml.transformers.text_classification\n",
            "       [-h]\n",
            "       --model_name_or_path\n",
            "       MODEL_NAME_OR_PATH\n",
            "       [--config_name CONFIG_NAME]\n",
            "       [--tokenizer_name TOKENIZER_NAME]\n",
            "       [--cache_dir CACHE_DIR]\n",
            "       [--use_fast_tokenizer [USE_FAST_TOKENIZER]]\n",
            "       [--no_use_fast_tokenizer]\n",
            "       [--use_teacher_tokenizer [USE_TEACHER_TOKENIZER]]\n",
            "       [--model_revision MODEL_REVISION]\n",
            "       [--use_auth_token [USE_AUTH_TOKEN]]\n",
            "       [--task_name TASK_NAME]\n",
            "       [--dataset_name DATASET_NAME]\n",
            "       [--dataset_config_name DATASET_CONFIG_NAME]\n",
            "       [--max_seq_length MAX_SEQ_LENGTH]\n",
            "       [--overwrite_cache [OVERWRITE_CACHE]]\n",
            "       [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
            "       [--pad_to_max_length [PAD_TO_MAX_LENGTH]]\n",
            "       [--no_pad_to_max_length]\n",
            "       [--max_train_samples MAX_TRAIN_SAMPLES]\n",
            "       [--max_eval_samples MAX_EVAL_SAMPLES]\n",
            "       [--max_predict_samples MAX_PREDICT_SAMPLES]\n",
            "       [--train_file TRAIN_FILE]\n",
            "       [--validation_file VALIDATION_FILE]\n",
            "       [--test_file TEST_FILE]\n",
            "       [--validation_ratio VALIDATION_RATIO]\n",
            "       [--eval_on_test [EVAL_ON_TEST]]\n",
            "       [--input_column_names INPUT_COLUMN_NAMES]\n",
            "       [--label_column_name LABEL_COLUMN_NAME]\n",
            "       [--one_shot [ONE_SHOT]]\n",
            "       [--num_export_samples NUM_EXPORT_SAMPLES]\n",
            "       --output_dir\n",
            "       OUTPUT_DIR\n",
            "       [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
            "       [--do_train [DO_TRAIN]]\n",
            "       [--do_eval [DO_EVAL]]\n",
            "       [--do_predict [DO_PREDICT]]\n",
            "       [--evaluation_strategy {no,steps,epoch}]\n",
            "       [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
            "       [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "       [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "       [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "       [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "       [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "       [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
            "       [--eval_delay EVAL_DELAY]\n",
            "       [--learning_rate LEARNING_RATE]\n",
            "       [--weight_decay WEIGHT_DECAY]\n",
            "       [--adam_beta1 ADAM_BETA1]\n",
            "       [--adam_beta2 ADAM_BETA2]\n",
            "       [--adam_epsilon ADAM_EPSILON]\n",
            "       [--max_grad_norm MAX_GRAD_NORM]\n",
            "       [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "       [--max_steps MAX_STEPS]\n",
            "       [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]\n",
            "       [--warmup_ratio WARMUP_RATIO]\n",
            "       [--warmup_steps WARMUP_STEPS]\n",
            "       [--log_level {debug,info,warning,error,critical,passive}]\n",
            "       [--log_level_replica {debug,info,warning,error,critical,passive}]\n",
            "       [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
            "       [--no_log_on_each_node]\n",
            "       [--logging_dir LOGGING_DIR]\n",
            "       [--logging_strategy {no,steps,epoch}]\n",
            "       [--logging_first_step [LOGGING_FIRST_STEP]]\n",
            "       [--logging_steps LOGGING_STEPS]\n",
            "       [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
            "       [--no_logging_nan_inf_filter]\n",
            "       [--save_strategy {no,steps,epoch}]\n",
            "       [--save_steps SAVE_STEPS]\n",
            "       [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "       [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
            "       [--no_cuda [NO_CUDA]]\n",
            "       [--use_mps_device [USE_MPS_DEVICE]]\n",
            "       [--seed SEED]\n",
            "       [--data_seed DATA_SEED]\n",
            "       [--jit_mode_eval [JIT_MODE_EVAL]]\n",
            "       [--use_ipex [USE_IPEX]]\n",
            "       [--bf16 [BF16]]\n",
            "       [--fp16 [FP16]]\n",
            "       [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "       [--half_precision_backend {auto,cuda_amp,apex,cpu_amp}]\n",
            "       [--bf16_full_eval [BF16_FULL_EVAL]]\n",
            "       [--fp16_full_eval [FP16_FULL_EVAL]]\n",
            "       [--tf32 TF32]\n",
            "       [--local_rank LOCAL_RANK]\n",
            "       [--xpu_backend {mpi,ccl}]\n",
            "       [--tpu_num_cores TPU_NUM_CORES]\n",
            "       [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
            "       [--debug DEBUG]\n",
            "       [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
            "       [--eval_steps EVAL_STEPS]\n",
            "       [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "       [--past_index PAST_INDEX]\n",
            "       [--run_name RUN_NAME]\n",
            "       [--disable_tqdm DISABLE_TQDM]\n",
            "       [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
            "       [--no_remove_unused_columns]\n",
            "       [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "       [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
            "       [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "       [--greater_is_better GREATER_IS_BETTER]\n",
            "       [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
            "       [--sharded_ddp SHARDED_DDP]\n",
            "       [--fsdp FSDP]\n",
            "       [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
            "       [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
            "       [--deepspeed DEEPSPEED]\n",
            "       [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
            "       [--optim {adamw_hf,adamw_torch,adamw_torch_xla,adamw_apex_fused,adafactor,adamw_bnb_8bit,sgd,adagrad}]\n",
            "       [--adafactor [ADAFACTOR]]\n",
            "       [--group_by_length [GROUP_BY_LENGTH]]\n",
            "       [--length_column_name LENGTH_COLUMN_NAME]\n",
            "       [--report_to REPORT_TO [REPORT_TO ...]]\n",
            "       [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
            "       [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
            "       [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
            "       [--no_dataloader_pin_memory]\n",
            "       [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
            "       [--no_skip_memory_metrics]\n",
            "       [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
            "       [--push_to_hub [PUSH_TO_HUB]]\n",
            "       [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "       [--hub_model_id HUB_MODEL_ID]\n",
            "       [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
            "       [--hub_token HUB_TOKEN]\n",
            "       [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
            "       [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
            "       [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
            "       [--fp16_backend {auto,cuda_amp,apex,cpu_amp}]\n",
            "       [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
            "       [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
            "       [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
            "       [--mp_parameters MP_PARAMETERS]\n",
            "       [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
            "       [--full_determinism [FULL_DETERMINISM]]\n",
            "       [--torchdynamo {eager,nvfuser,fx2trt,fx2trt-fp16}]\n",
            "       [--ray_scope RAY_SCOPE]\n",
            "       [--ddp_timeout DDP_TIMEOUT]\n",
            "       [--distill_teacher DISTILL_TEACHER]\n",
            "       [--best_model_after_epoch BEST_MODEL_AFTER_EPOCH]\n",
            "       [--recipe RECIPE]\n",
            "       [--recipe_args RECIPE_ARGS]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model_name_or_path MODEL_NAME_OR_PATH\n",
            "    Path to\n",
            "    pretrained\n",
            "    model,\n",
            "    sparsezoo\n",
            "    stub. or\n",
            "    model\n",
            "    identifier\n",
            "    from huggin\n",
            "    gface.co/mo\n",
            "    dels\n",
            "    (default:\n",
            "    None)\n",
            "  --config_name CONFIG_NAME\n",
            "    Pretrained\n",
            "    config name\n",
            "    or path if\n",
            "    not the\n",
            "    same as\n",
            "    model_name\n",
            "    (default:\n",
            "    None)\n",
            "  --tokenizer_name TOKENIZER_NAME\n",
            "    Pretrained\n",
            "    tokenizer\n",
            "    name or\n",
            "    path if not\n",
            "    the same as\n",
            "    model_name\n",
            "    (default:\n",
            "    None)\n",
            "  --cache_dir CACHE_DIR\n",
            "    Where to\n",
            "    store the\n",
            "    pretrained\n",
            "    data from h\n",
            "    uggingface.\n",
            "    co\n",
            "    (default:\n",
            "    None)\n",
            "  --use_fast_tokenizer [USE_FAST_TOKENIZER]\n",
            "    Whether to\n",
            "    use one of\n",
            "    the fast\n",
            "    tokenizers.\n",
            "    Default\n",
            "    True\n",
            "    (default:\n",
            "    True)\n",
            "  --no_use_fast_tokenizer\n",
            "    Whether to\n",
            "    use one of\n",
            "    the fast\n",
            "    tokenizers.\n",
            "    Default\n",
            "    True\n",
            "    (default:\n",
            "    False)\n",
            "  --use_teacher_tokenizer [USE_TEACHER_TOKENIZER]\n",
            "    Whether to\n",
            "    use\n",
            "    separate\n",
            "    tokenizer\n",
            "    for distill\n",
            "    ation\n",
            "    teacher.\n",
            "    Default\n",
            "    False; uses\n",
            "    same\n",
            "    tokenizer\n",
            "    for teacher\n",
            "    and student\n",
            "    (default:\n",
            "    False)\n",
            "  --model_revision MODEL_REVISION\n",
            "    The\n",
            "    specific\n",
            "    model\n",
            "    version to\n",
            "    use (can be\n",
            "    a branch\n",
            "    name, tag\n",
            "    name or\n",
            "    commit id)\n",
            "    (default:\n",
            "    main)\n",
            "  --use_auth_token [USE_AUTH_TOKEN]\n",
            "    Will use\n",
            "    token\n",
            "    generated\n",
            "    when\n",
            "    running `tr\n",
            "    ansformers-\n",
            "    cli login`\n",
            "    (necessary\n",
            "    to use this\n",
            "    script with\n",
            "    private\n",
            "    models)\n",
            "    (default:\n",
            "    False)\n",
            "  --task_name TASK_NAME\n",
            "    The name of\n",
            "    the task to\n",
            "    train on:\n",
            "    cola, mnli,\n",
            "    mrpc, qnli,\n",
            "    qqp, rte,\n",
            "    sst2, stsb,\n",
            "    wnli, imdb\n",
            "    (default:\n",
            "    None)\n",
            "  --dataset_name DATASET_NAME\n",
            "    The name of\n",
            "    the dataset\n",
            "    to use (via\n",
            "    the\n",
            "    datasets\n",
            "    library)\n",
            "    (default:\n",
            "    None)\n",
            "  --dataset_config_name DATASET_CONFIG_NAME\n",
            "    The configu\n",
            "    ration name\n",
            "    of the\n",
            "    dataset to\n",
            "    use\n",
            "    (default:\n",
            "    None)\n",
            "  --max_seq_length MAX_SEQ_LENGTH\n",
            "    The maximum\n",
            "    total input\n",
            "    sequence\n",
            "    length\n",
            "    after token\n",
            "    ization.\n",
            "    Sequences\n",
            "    longer than\n",
            "    this will\n",
            "    be\n",
            "    truncated,\n",
            "    sequences\n",
            "    shorter\n",
            "    will be\n",
            "    padded.\n",
            "    (default:\n",
            "    384)\n",
            "  --overwrite_cache [OVERWRITE_CACHE]\n",
            "    Overwrite\n",
            "    the cached \n",
            "    preprocesse\n",
            "    d datasets\n",
            "    or not.\n",
            "    (default:\n",
            "    False)\n",
            "  --preprocessing_num_workers PREPROCESSING_NUM_WORKERS\n",
            "    The number\n",
            "    of\n",
            "    processes\n",
            "    to use for\n",
            "    the preproc\n",
            "    essing.\n",
            "    (default:\n",
            "    None)\n",
            "  --pad_to_max_length [PAD_TO_MAX_LENGTH]\n",
            "    Whether to\n",
            "    pad all\n",
            "    samples to \n",
            "    `max_seq_le\n",
            "    ngth`. If\n",
            "    False, will\n",
            "    pad the\n",
            "    samples\n",
            "    dynamically\n",
            "    when\n",
            "    batching to\n",
            "    the maximum\n",
            "    length in\n",
            "    the batch\n",
            "    (which can\n",
            "    be faster\n",
            "    on GPU but\n",
            "    will be\n",
            "    slower on\n",
            "    TPU).\n",
            "    (default:\n",
            "    True)\n",
            "  --no_pad_to_max_length\n",
            "    Whether to\n",
            "    pad all\n",
            "    samples to \n",
            "    `max_seq_le\n",
            "    ngth`. If\n",
            "    False, will\n",
            "    pad the\n",
            "    samples\n",
            "    dynamically\n",
            "    when\n",
            "    batching to\n",
            "    the maximum\n",
            "    length in\n",
            "    the batch\n",
            "    (which can\n",
            "    be faster\n",
            "    on GPU but\n",
            "    will be\n",
            "    slower on\n",
            "    TPU).\n",
            "    (default:\n",
            "    False)\n",
            "  --max_train_samples MAX_TRAIN_SAMPLES\n",
            "    For\n",
            "    debugging\n",
            "    purposes or\n",
            "    quicker\n",
            "    training,\n",
            "    truncate\n",
            "    the number\n",
            "    of training\n",
            "    examples to\n",
            "    this value\n",
            "    if set.\n",
            "    (default:\n",
            "    None)\n",
            "  --max_eval_samples MAX_EVAL_SAMPLES\n",
            "    For\n",
            "    debugging\n",
            "    purposes or\n",
            "    quicker\n",
            "    training,\n",
            "    truncate\n",
            "    the number\n",
            "    of\n",
            "    evaluation\n",
            "    examples to\n",
            "    this value\n",
            "    if set.\n",
            "    (default:\n",
            "    None)\n",
            "  --max_predict_samples MAX_PREDICT_SAMPLES\n",
            "    For\n",
            "    debugging\n",
            "    purposes or\n",
            "    quicker\n",
            "    training,\n",
            "    truncate\n",
            "    the number\n",
            "    of\n",
            "    prediction\n",
            "    examples to\n",
            "    this value\n",
            "    if set.\n",
            "    (default:\n",
            "    None)\n",
            "  --train_file TRAIN_FILE\n",
            "    A csv or a\n",
            "    json file\n",
            "    containing\n",
            "    the\n",
            "    training\n",
            "    data.\n",
            "    (default:\n",
            "    None)\n",
            "  --validation_file VALIDATION_FILE\n",
            "    A csv or a\n",
            "    json file\n",
            "    containing\n",
            "    the\n",
            "    validation\n",
            "    data.\n",
            "    (default:\n",
            "    None)\n",
            "  --test_file TEST_FILE\n",
            "    A csv or a\n",
            "    json file\n",
            "    containing\n",
            "    the test\n",
            "    data.\n",
            "    (default:\n",
            "    None)\n",
            "  --validation_ratio VALIDATION_RATIO\n",
            "    Percentage\n",
            "    of the\n",
            "    training\n",
            "    data to be\n",
            "    used as\n",
            "    validation.\n",
            "    (default:\n",
            "    None)\n",
            "  --eval_on_test [EVAL_ON_TEST]\n",
            "    Evaluate\n",
            "    the test\n",
            "    dataset.\n",
            "    (default:\n",
            "    False)\n",
            "  --input_column_names INPUT_COLUMN_NAMES\n",
            "    name of\n",
            "    column to\n",
            "    read model\n",
            "    input data\n",
            "    from. May\n",
            "    also be\n",
            "    comma\n",
            "    separated\n",
            "    list of two\n",
            "    columns to\n",
            "    use as\n",
            "    inputs.\n",
            "    Examples\n",
            "    include\n",
            "    'sentence'\n",
            "    for single\n",
            "    column and \n",
            "    'sentence_1\n",
            "    ,sentence_2\n",
            "    ' for two.\n",
            "    Default\n",
            "    behavior is\n",
            "    to read\n",
            "    columns\n",
            "    based on\n",
            "    task name\n",
            "    or infer\n",
            "    from non\n",
            "    'label'\n",
            "    columns if \n",
            "    sentence_co\n",
            "    lumn_names\n",
            "    and task\n",
            "    name\n",
            "    notprovided\n",
            "    (default:\n",
            "    None)\n",
            "  --label_column_name LABEL_COLUMN_NAME\n",
            "    column in\n",
            "    dataset\n",
            "    where input\n",
            "    labels are\n",
            "    located.\n",
            "    Default is\n",
            "    'label'\n",
            "    (default:\n",
            "    label)\n",
            "  --one_shot [ONE_SHOT]\n",
            "    Whether to\n",
            "    apply\n",
            "    recipe in a\n",
            "    one shot\n",
            "    manner.\n",
            "    (default:\n",
            "    False)\n",
            "  --num_export_samples NUM_EXPORT_SAMPLES\n",
            "    Number of\n",
            "    samples (in\n",
            "    puts/output\n",
            "    s) to\n",
            "    export\n",
            "    during\n",
            "    eval.\n",
            "    (default:\n",
            "    0)\n",
            "  --output_dir OUTPUT_DIR\n",
            "    The output\n",
            "    directory\n",
            "    where the\n",
            "    model\n",
            "    predictions\n",
            "    and\n",
            "    checkpoints\n",
            "    will be\n",
            "    written.\n",
            "    (default:\n",
            "    None)\n",
            "  --overwrite_output_dir [OVERWRITE_OUTPUT_DIR]\n",
            "    Overwrite\n",
            "    the content\n",
            "    of the\n",
            "    output\n",
            "    directory.\n",
            "    Use this to\n",
            "    continue\n",
            "    training if\n",
            "    output_dir\n",
            "    points to a\n",
            "    checkpoint\n",
            "    directory.\n",
            "    (default:\n",
            "    False)\n",
            "  --do_train [DO_TRAIN]\n",
            "    Whether to\n",
            "    run\n",
            "    training.\n",
            "    (default:\n",
            "    False)\n",
            "  --do_eval [DO_EVAL]\n",
            "    Whether to\n",
            "    run eval on\n",
            "    the dev\n",
            "    set.\n",
            "    (default:\n",
            "    False)\n",
            "  --do_predict [DO_PREDICT]\n",
            "    Whether to\n",
            "    run\n",
            "    predictions\n",
            "    on the test\n",
            "    set.\n",
            "    (default:\n",
            "    False)\n",
            "  --evaluation_strategy {no,steps,epoch}\n",
            "    The\n",
            "    evaluation\n",
            "    strategy to\n",
            "    use.\n",
            "    (default:\n",
            "    no)\n",
            "  --prediction_loss_only [PREDICTION_LOSS_ONLY]\n",
            "    When\n",
            "    performing\n",
            "    evaluation\n",
            "    and predict\n",
            "    ions, only\n",
            "    returns the\n",
            "    loss.\n",
            "    (default:\n",
            "    False)\n",
            "  --per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE\n",
            "    Batch size\n",
            "    per GPU/TPU\n",
            "    core/CPU\n",
            "    for\n",
            "    training.\n",
            "    (default:\n",
            "    8)\n",
            "  --per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE\n",
            "    Batch size\n",
            "    per GPU/TPU\n",
            "    core/CPU\n",
            "    for\n",
            "    evaluation.\n",
            "    (default:\n",
            "    8)\n",
            "  --per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE\n",
            "    Deprecated,\n",
            "    the use of \n",
            "    `--per_devi\n",
            "    ce_train_ba\n",
            "    tch_size`\n",
            "    is\n",
            "    preferred.\n",
            "    Batch size\n",
            "    per GPU/TPU\n",
            "    core/CPU\n",
            "    for\n",
            "    training.\n",
            "    (default:\n",
            "    None)\n",
            "  --per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE\n",
            "    Deprecated,\n",
            "    the use of \n",
            "    `--per_devi\n",
            "    ce_eval_bat\n",
            "    ch_size` is\n",
            "    preferred.\n",
            "    Batch size\n",
            "    per GPU/TPU\n",
            "    core/CPU\n",
            "    for\n",
            "    evaluation.\n",
            "    (default:\n",
            "    None)\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
            "    Number of\n",
            "    updates\n",
            "    steps to\n",
            "    accumulate\n",
            "    before\n",
            "    performing\n",
            "    a backward/\n",
            "    update\n",
            "    pass.\n",
            "    (default:\n",
            "    1)\n",
            "  --eval_accumulation_steps EVAL_ACCUMULATION_STEPS\n",
            "    Number of\n",
            "    predictions\n",
            "    steps to\n",
            "    accumulate\n",
            "    before\n",
            "    moving the\n",
            "    tensors to\n",
            "    the CPU.\n",
            "    (default:\n",
            "    None)\n",
            "  --eval_delay EVAL_DELAY\n",
            "    Number of\n",
            "    epochs or\n",
            "    steps to\n",
            "    wait for\n",
            "    before the\n",
            "    first\n",
            "    evaluation\n",
            "    can be\n",
            "    performed,\n",
            "    depending\n",
            "    on the eval\n",
            "    uation_stra\n",
            "    tegy.\n",
            "    (default:\n",
            "    0)\n",
            "  --learning_rate LEARNING_RATE\n",
            "    The initial\n",
            "    learning\n",
            "    rate for\n",
            "    AdamW.\n",
            "    (default:\n",
            "    5e-05)\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "    Weight\n",
            "    decay for\n",
            "    AdamW if we\n",
            "    apply some.\n",
            "    (default:\n",
            "    0.0)\n",
            "  --adam_beta1 ADAM_BETA1\n",
            "    Beta1 for\n",
            "    AdamW\n",
            "    optimizer\n",
            "    (default:\n",
            "    0.9)\n",
            "  --adam_beta2 ADAM_BETA2\n",
            "    Beta2 for\n",
            "    AdamW\n",
            "    optimizer\n",
            "    (default:\n",
            "    0.999)\n",
            "  --adam_epsilon ADAM_EPSILON\n",
            "    Epsilon for\n",
            "    AdamW\n",
            "    optimizer.\n",
            "    (default:\n",
            "    1e-08)\n",
            "  --max_grad_norm MAX_GRAD_NORM\n",
            "    Max\n",
            "    gradient\n",
            "    norm.\n",
            "    (default:\n",
            "    1.0)\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS\n",
            "    Total\n",
            "    number of\n",
            "    training\n",
            "    epochs to\n",
            "    perform.\n",
            "    (default:\n",
            "    3.0)\n",
            "  --max_steps MAX_STEPS\n",
            "    If > 0: set\n",
            "    total\n",
            "    number of\n",
            "    training\n",
            "    steps to\n",
            "    perform.\n",
            "    Override nu\n",
            "    m_train_epo\n",
            "    chs.\n",
            "    (default:\n",
            "    -1)\n",
            "  --lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}\n",
            "    The\n",
            "    scheduler\n",
            "    type to\n",
            "    use.\n",
            "    (default:\n",
            "    linear)\n",
            "  --warmup_ratio WARMUP_RATIO\n",
            "    Linear\n",
            "    warmup over\n",
            "    warmup_rati\n",
            "    o fraction\n",
            "    of total\n",
            "    steps.\n",
            "    (default:\n",
            "    0.0)\n",
            "  --warmup_steps WARMUP_STEPS\n",
            "    Linear\n",
            "    warmup over\n",
            "    warmup_step\n",
            "    s.\n",
            "    (default:\n",
            "    0)\n",
            "  --log_level {debug,info,warning,error,critical,passive}\n",
            "    Logger log\n",
            "    level to\n",
            "    use on the\n",
            "    main node.\n",
            "    Possible\n",
            "    choices are\n",
            "    the log\n",
            "    levels as\n",
            "    strings:\n",
            "    'debug',\n",
            "    'info',\n",
            "    'warning',\n",
            "    'error' and\n",
            "    'critical',\n",
            "    plus a\n",
            "    'passive'\n",
            "    level which\n",
            "    doesn't set\n",
            "    anything\n",
            "    and lets\n",
            "    the\n",
            "    application\n",
            "    set the\n",
            "    level.\n",
            "    Defaults to\n",
            "    'passive'.\n",
            "    (default:\n",
            "    passive)\n",
            "  --log_level_replica {debug,info,warning,error,critical,passive}\n",
            "    Logger log\n",
            "    level to\n",
            "    use on\n",
            "    replica\n",
            "    nodes. Same\n",
            "    choices and\n",
            "    defaults as\n",
            "    ``log_level\n",
            "    ``\n",
            "    (default:\n",
            "    passive)\n",
            "  --log_on_each_node [LOG_ON_EACH_NODE]\n",
            "    When doing\n",
            "    a multinode\n",
            "    distributed\n",
            "    training,\n",
            "    whether to\n",
            "    log once\n",
            "    per node or\n",
            "    just once\n",
            "    on the main\n",
            "    node.\n",
            "    (default:\n",
            "    True)\n",
            "  --no_log_on_each_node\n",
            "    When doing\n",
            "    a multinode\n",
            "    distributed\n",
            "    training,\n",
            "    whether to\n",
            "    log once\n",
            "    per node or\n",
            "    just once\n",
            "    on the main\n",
            "    node.\n",
            "    (default:\n",
            "    False)\n",
            "  --logging_dir LOGGING_DIR\n",
            "    Tensorboard\n",
            "    log dir.\n",
            "    (default:\n",
            "    None)\n",
            "  --logging_strategy {no,steps,epoch}\n",
            "    The logging\n",
            "    strategy to\n",
            "    use.\n",
            "    (default:\n",
            "    steps)\n",
            "  --logging_first_step [LOGGING_FIRST_STEP]\n",
            "    Log the\n",
            "    first\n",
            "    global_step\n",
            "    (default:\n",
            "    False)\n",
            "  --logging_steps LOGGING_STEPS\n",
            "    Log every X\n",
            "    updates\n",
            "    steps.\n",
            "    (default:\n",
            "    500)\n",
            "  --logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]\n",
            "    Filter nan\n",
            "    and inf\n",
            "    losses for\n",
            "    logging.\n",
            "    (default:\n",
            "    True)\n",
            "  --no_logging_nan_inf_filter\n",
            "    Filter nan\n",
            "    and inf\n",
            "    losses for\n",
            "    logging.\n",
            "    (default:\n",
            "    False)\n",
            "  --save_strategy {no,steps,epoch}\n",
            "    The\n",
            "    checkpoint\n",
            "    save\n",
            "    strategy to\n",
            "    use.\n",
            "    (default:\n",
            "    steps)\n",
            "  --save_steps SAVE_STEPS\n",
            "    Save\n",
            "    checkpoint\n",
            "    every X\n",
            "    updates\n",
            "    steps.\n",
            "    (default:\n",
            "    500)\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT\n",
            "    Limit the\n",
            "    total\n",
            "    amount of c\n",
            "    heckpoints.\n",
            "    Deletes the\n",
            "    older\n",
            "    checkpoints\n",
            "    in the\n",
            "    output_dir.\n",
            "    Default is\n",
            "    unlimited\n",
            "    checkpoints\n",
            "    (default:\n",
            "    None)\n",
            "  --save_on_each_node [SAVE_ON_EACH_NODE]\n",
            "    When doing\n",
            "    multi-node\n",
            "    distributed\n",
            "    training,\n",
            "    whether to\n",
            "    save models\n",
            "    and\n",
            "    checkpoints\n",
            "    on each\n",
            "    node, or\n",
            "    only on the\n",
            "    main one\n",
            "    (default:\n",
            "    False)\n",
            "  --no_cuda [NO_CUDA]\n",
            "    Do not use\n",
            "    CUDA even\n",
            "    when it is\n",
            "    available\n",
            "    (default:\n",
            "    False)\n",
            "  --use_mps_device [USE_MPS_DEVICE]\n",
            "    Whether to\n",
            "    use Apple\n",
            "    Silicon\n",
            "    chip based\n",
            "    `mps`\n",
            "    device.\n",
            "    (default:\n",
            "    False)\n",
            "  --seed SEED\n",
            "    Random seed\n",
            "    that will\n",
            "    be set at\n",
            "    the\n",
            "    beginning\n",
            "    of\n",
            "    training.\n",
            "    (default:\n",
            "    42)\n",
            "  --data_seed DATA_SEED\n",
            "    Random seed\n",
            "    to be used\n",
            "    with data\n",
            "    samplers.\n",
            "    (default:\n",
            "    None)\n",
            "  --jit_mode_eval [JIT_MODE_EVAL]\n",
            "    Whether or\n",
            "    not to use\n",
            "    PyTorch jit\n",
            "    trace for\n",
            "    inference\n",
            "    (default:\n",
            "    False)\n",
            "  --use_ipex [USE_IPEX]\n",
            "    Use Intel\n",
            "    extension\n",
            "    for PyTorch\n",
            "    when it is\n",
            "    available, \n",
            "    installatio\n",
            "    n: 'https:/\n",
            "    /github.com\n",
            "    /intel/inte\n",
            "    l-\n",
            "    extension-\n",
            "    for-\n",
            "    pytorch'\n",
            "    (default:\n",
            "    False)\n",
            "  --bf16 [BF16]\n",
            "    Whether to\n",
            "    use bf16\n",
            "    (mixed)\n",
            "    precision\n",
            "    instead of\n",
            "    32-bit.\n",
            "    Requires\n",
            "    Ampere or\n",
            "    higher\n",
            "    NVIDIA arch\n",
            "    itecture or\n",
            "    using CPU\n",
            "    (no_cuda).\n",
            "    This is an \n",
            "    experimenta\n",
            "    l API and\n",
            "    it may\n",
            "    change.\n",
            "    (default:\n",
            "    False)\n",
            "  --fp16 [FP16]\n",
            "    Whether to\n",
            "    use fp16\n",
            "    (mixed)\n",
            "    precision\n",
            "    instead of\n",
            "    32-bit\n",
            "    (default:\n",
            "    False)\n",
            "  --fp16_opt_level FP16_OPT_LEVEL\n",
            "    For fp16:\n",
            "    Apex AMP op\n",
            "    timization\n",
            "    level\n",
            "    selected in\n",
            "    ['O0',\n",
            "    'O1', 'O2',\n",
            "    and 'O3'].\n",
            "    See details\n",
            "    at https://\n",
            "    nvidia.gith\n",
            "    ub.io/apex/\n",
            "    amp.html\n",
            "    (default:\n",
            "    O1)\n",
            "  --half_precision_backend {auto,cuda_amp,apex,cpu_amp}\n",
            "    The backend\n",
            "    to be used\n",
            "    for half\n",
            "    precision.\n",
            "    (default:\n",
            "    auto)\n",
            "  --bf16_full_eval [BF16_FULL_EVAL]\n",
            "    Whether to\n",
            "    use full\n",
            "    bfloat16\n",
            "    evaluation\n",
            "    instead of\n",
            "    32-bit.\n",
            "    This is an \n",
            "    experimenta\n",
            "    l API and\n",
            "    it may\n",
            "    change.\n",
            "    (default:\n",
            "    False)\n",
            "  --fp16_full_eval [FP16_FULL_EVAL]\n",
            "    Whether to\n",
            "    use full\n",
            "    float16\n",
            "    evaluation\n",
            "    instead of\n",
            "    32-bit\n",
            "    (default:\n",
            "    False)\n",
            "  --tf32 TF32\n",
            "    Whether to\n",
            "    enable tf32\n",
            "    mode,\n",
            "    available\n",
            "    in Ampere\n",
            "    and newer\n",
            "    GPU archite\n",
            "    ctures.\n",
            "    This is an \n",
            "    experimenta\n",
            "    l API and\n",
            "    it may\n",
            "    change.\n",
            "    (default:\n",
            "    None)\n",
            "  --local_rank LOCAL_RANK\n",
            "    For\n",
            "    distributed\n",
            "    training:\n",
            "    local_rank\n",
            "    (default:\n",
            "    -1)\n",
            "  --xpu_backend {mpi,ccl}\n",
            "    The backend\n",
            "    to be used\n",
            "    for\n",
            "    distributed\n",
            "    training on\n",
            "    Intel XPU.\n",
            "    (default:\n",
            "    None)\n",
            "  --tpu_num_cores TPU_NUM_CORES\n",
            "    TPU: Number\n",
            "    of TPU\n",
            "    cores (auto\n",
            "    matically\n",
            "    passed by\n",
            "    launcher\n",
            "    script)\n",
            "    (default:\n",
            "    None)\n",
            "  --tpu_metrics_debug [TPU_METRICS_DEBUG]\n",
            "    Deprecated,\n",
            "    the use of\n",
            "    `--debug tp\n",
            "    u_metrics_d\n",
            "    ebug` is\n",
            "    preferred.\n",
            "    TPU:\n",
            "    Whether to\n",
            "    print debug\n",
            "    metrics\n",
            "    (default:\n",
            "    False)\n",
            "  --debug DEBUG\n",
            "    Whether or\n",
            "    not to\n",
            "    enable\n",
            "    debug mode.\n",
            "    Current\n",
            "    options: `u\n",
            "    nderflow_ov\n",
            "    erflow`\n",
            "    (Detect\n",
            "    underflow\n",
            "    and\n",
            "    overflow in\n",
            "    activations\n",
            "    and\n",
            "    weights), `\n",
            "    tpu_metrics\n",
            "    _debug`\n",
            "    (print\n",
            "    debug\n",
            "    metrics on\n",
            "    TPU).\n",
            "    (default: )\n",
            "  --dataloader_drop_last [DATALOADER_DROP_LAST]\n",
            "    Drop the\n",
            "    last\n",
            "    incomplete\n",
            "    batch if it\n",
            "    is not\n",
            "    divisible\n",
            "    by the\n",
            "    batch size.\n",
            "    (default:\n",
            "    False)\n",
            "  --eval_steps EVAL_STEPS\n",
            "    Run an\n",
            "    evaluation\n",
            "    every X\n",
            "    steps.\n",
            "    (default:\n",
            "    None)\n",
            "  --dataloader_num_workers DATALOADER_NUM_WORKERS\n",
            "    Number of s\n",
            "    ubprocesses\n",
            "    to use for\n",
            "    data\n",
            "    loading\n",
            "    (PyTorch\n",
            "    only). 0\n",
            "    means that\n",
            "    the data\n",
            "    will be\n",
            "    loaded in\n",
            "    the main\n",
            "    process.\n",
            "    (default:\n",
            "    0)\n",
            "  --past_index PAST_INDEX\n",
            "    If >=0,\n",
            "    uses the co\n",
            "    rresponding\n",
            "    part of the\n",
            "    output as\n",
            "    the past\n",
            "    state for\n",
            "    next step.\n",
            "    (default:\n",
            "    -1)\n",
            "  --run_name RUN_NAME\n",
            "    An optional\n",
            "    descriptor\n",
            "    for the\n",
            "    run.\n",
            "    Notably\n",
            "    used for\n",
            "    wandb\n",
            "    logging.\n",
            "    (default:\n",
            "    None)\n",
            "  --disable_tqdm DISABLE_TQDM\n",
            "    Whether or\n",
            "    not to\n",
            "    disable the\n",
            "    tqdm\n",
            "    progress\n",
            "    bars.\n",
            "    (default:\n",
            "    None)\n",
            "  --remove_unused_columns [REMOVE_UNUSED_COLUMNS]\n",
            "    Remove\n",
            "    columns not\n",
            "    required by\n",
            "    the model\n",
            "    when using\n",
            "    an nlp.Data\n",
            "    set.\n",
            "    (default:\n",
            "    True)\n",
            "  --no_remove_unused_columns\n",
            "    Remove\n",
            "    columns not\n",
            "    required by\n",
            "    the model\n",
            "    when using\n",
            "    an nlp.Data\n",
            "    set.\n",
            "    (default:\n",
            "    False)\n",
            "  --label_names LABEL_NAMES [LABEL_NAMES ...]\n",
            "    The list of\n",
            "    keys in\n",
            "    your\n",
            "    dictionary\n",
            "    of inputs\n",
            "    that\n",
            "    correspond\n",
            "    to the\n",
            "    labels.\n",
            "    (default:\n",
            "    None)\n",
            "  --load_best_model_at_end [LOAD_BEST_MODEL_AT_END]\n",
            "    Whether or\n",
            "    not to load\n",
            "    the best\n",
            "    model found\n",
            "    during\n",
            "    training at\n",
            "    the end of\n",
            "    training.\n",
            "    (default:\n",
            "    False)\n",
            "  --metric_for_best_model METRIC_FOR_BEST_MODEL\n",
            "    The metric\n",
            "    to use to\n",
            "    compare two\n",
            "    different\n",
            "    models.\n",
            "    (default:\n",
            "    None)\n",
            "  --greater_is_better GREATER_IS_BETTER\n",
            "    Whether the\n",
            "    `metric_for\n",
            "    _best_model\n",
            "    ` should be\n",
            "    maximized\n",
            "    or not.\n",
            "    (default:\n",
            "    None)\n",
            "  --ignore_data_skip [IGNORE_DATA_SKIP]\n",
            "    When\n",
            "    resuming\n",
            "    training,\n",
            "    whether or\n",
            "    not to skip\n",
            "    the first\n",
            "    epochs and\n",
            "    batches to\n",
            "    get to the\n",
            "    same\n",
            "    training\n",
            "    data.\n",
            "    (default:\n",
            "    False)\n",
            "  --sharded_ddp SHARDED_DDP\n",
            "    Whether or\n",
            "    not to use\n",
            "    sharded DDP\n",
            "    training\n",
            "    (in\n",
            "    distributed\n",
            "    training\n",
            "    only). The\n",
            "    base option\n",
            "    should be\n",
            "    `simple`,\n",
            "    `zero_dp_2`\n",
            "    or\n",
            "    `zero_dp_3`\n",
            "    and you can\n",
            "    add CPU-\n",
            "    offload to\n",
            "    `zero_dp_2`\n",
            "    or\n",
            "    `zero_dp_3`\n",
            "    like this:\n",
            "    zero_dp_2\n",
            "    offload` or\n",
            "    `zero_dp_3\n",
            "    offload`.\n",
            "    You can add\n",
            "    auto-wrap\n",
            "    to\n",
            "    `zero_dp_2`\n",
            "    or\n",
            "    `zero_dp_3`\n",
            "    with the\n",
            "    same\n",
            "    syntax:\n",
            "    zero_dp_2\n",
            "    auto_wrap`\n",
            "    or\n",
            "    `zero_dp_3\n",
            "    auto_wrap`.\n",
            "    (default: )\n",
            "  --fsdp FSDP\n",
            "    Whether or\n",
            "    not to use\n",
            "    PyTorch\n",
            "    Fully\n",
            "    Sharded\n",
            "    Data\n",
            "    Parallel\n",
            "    (FSDP)\n",
            "    training\n",
            "    (in\n",
            "    distributed\n",
            "    training\n",
            "    only). The\n",
            "    base option\n",
            "    should be `\n",
            "    full_shard`\n",
            "    , `shard_gr\n",
            "    ad_op` or\n",
            "    `no_shard`\n",
            "    and you can\n",
            "    add CPU-\n",
            "    offload to \n",
            "    `full_shard\n",
            "    ` or `shard\n",
            "    _grad_op`\n",
            "    like this:\n",
            "    full_shard\n",
            "    offload` or\n",
            "    `shard_grad\n",
            "    _op\n",
            "    offload`.\n",
            "    You can add\n",
            "    auto-wrap\n",
            "    to `full_sh\n",
            "    ard` or `sh\n",
            "    ard_grad_op\n",
            "    ` with the\n",
            "    same\n",
            "    syntax:\n",
            "    full_shard\n",
            "    auto_wrap`\n",
            "    or `shard_g\n",
            "    rad_op\n",
            "    auto_wrap`.\n",
            "    (default: )\n",
            "  --fsdp_min_num_params FSDP_MIN_NUM_PARAMS\n",
            "    FSDP's\n",
            "    minimum\n",
            "    number of\n",
            "    parameters\n",
            "    for Default\n",
            "    Auto\n",
            "    Wrapping.\n",
            "    (useful\n",
            "    only when\n",
            "    `fsdp`\n",
            "    field is\n",
            "    passed).\n",
            "    (default:\n",
            "    0)\n",
            "  --fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP\n",
            "    Transformer\n",
            "    layer class\n",
            "    name (case-\n",
            "    sensitive)\n",
            "    to wrap\n",
            "    ,e.g, `Bert\n",
            "    Layer`, `GP\n",
            "    TJBlock`,\n",
            "    `T5Block`\n",
            "    ....\n",
            "    (useful\n",
            "    only when\n",
            "    `fsdp` flag\n",
            "    is passed).\n",
            "    (default:\n",
            "    None)\n",
            "  --deepspeed DEEPSPEED\n",
            "    Enable\n",
            "    deepspeed\n",
            "    and pass\n",
            "    the path to\n",
            "    deepspeed\n",
            "    json config\n",
            "    file (e.g. \n",
            "    ds_config.j\n",
            "    son) or an\n",
            "    already\n",
            "    loaded json\n",
            "    file as a\n",
            "    dict\n",
            "    (default:\n",
            "    None)\n",
            "  --label_smoothing_factor LABEL_SMOOTHING_FACTOR\n",
            "    The label\n",
            "    smoothing\n",
            "    epsilon to\n",
            "    apply (zero\n",
            "    means no\n",
            "    label\n",
            "    smoothing).\n",
            "    (default:\n",
            "    0.0)\n",
            "  --optim {adamw_hf,adamw_torch,adamw_torch_xla,adamw_apex_fused,adafactor,adamw_bnb_8bit,sgd,adagrad}\n",
            "    The\n",
            "    optimizer\n",
            "    to use.\n",
            "    (default:\n",
            "    adamw_hf)\n",
            "  --adafactor [ADAFACTOR]\n",
            "    Whether or\n",
            "    not to\n",
            "    replace\n",
            "    AdamW by\n",
            "    Adafactor.\n",
            "    (default:\n",
            "    False)\n",
            "  --group_by_length [GROUP_BY_LENGTH]\n",
            "    Whether or\n",
            "    not to\n",
            "    group\n",
            "    samples of\n",
            "    roughly the\n",
            "    same length\n",
            "    together\n",
            "    when\n",
            "    batching.\n",
            "    (default:\n",
            "    False)\n",
            "  --length_column_name LENGTH_COLUMN_NAME\n",
            "    Column name\n",
            "    with\n",
            "    precomputed\n",
            "    lengths to\n",
            "    use when\n",
            "    grouping by\n",
            "    length.\n",
            "    (default:\n",
            "    length)\n",
            "  --report_to REPORT_TO [REPORT_TO ...]\n",
            "    The list of\n",
            "    integration\n",
            "    s to report\n",
            "    the results\n",
            "    and logs\n",
            "    to.\n",
            "    (default:\n",
            "    None)\n",
            "  --ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS\n",
            "    When using\n",
            "    distributed\n",
            "    training,\n",
            "    the value\n",
            "    of the flag\n",
            "    `find_unuse\n",
            "    d_parameter\n",
            "    s` passed\n",
            "    to `Distrib\n",
            "    utedDataPar\n",
            "    allel`.\n",
            "    (default:\n",
            "    None)\n",
            "  --ddp_bucket_cap_mb DDP_BUCKET_CAP_MB\n",
            "    When using\n",
            "    distributed\n",
            "    training,\n",
            "    the value\n",
            "    of the flag\n",
            "    `bucket_cap\n",
            "    _mb` passed\n",
            "    to `Distrib\n",
            "    utedDataPar\n",
            "    allel`.\n",
            "    (default:\n",
            "    None)\n",
            "  --dataloader_pin_memory [DATALOADER_PIN_MEMORY]\n",
            "    Whether or\n",
            "    not to pin\n",
            "    memory for\n",
            "    DataLoader.\n",
            "    (default:\n",
            "    True)\n",
            "  --no_dataloader_pin_memory\n",
            "    Whether or\n",
            "    not to pin\n",
            "    memory for\n",
            "    DataLoader.\n",
            "    (default:\n",
            "    False)\n",
            "  --skip_memory_metrics [SKIP_MEMORY_METRICS]\n",
            "    Whether or\n",
            "    not to skip\n",
            "    adding of\n",
            "    memory\n",
            "    profiler\n",
            "    reports to\n",
            "    metrics.\n",
            "    (default:\n",
            "    True)\n",
            "  --no_skip_memory_metrics\n",
            "    Whether or\n",
            "    not to skip\n",
            "    adding of\n",
            "    memory\n",
            "    profiler\n",
            "    reports to\n",
            "    metrics.\n",
            "    (default:\n",
            "    False)\n",
            "  --use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]\n",
            "    Whether or\n",
            "    not to use\n",
            "    the legacy \n",
            "    prediction_\n",
            "    loop in the\n",
            "    Trainer.\n",
            "    (default:\n",
            "    False)\n",
            "  --push_to_hub [PUSH_TO_HUB]\n",
            "    Whether or\n",
            "    not to\n",
            "    upload the\n",
            "    trained\n",
            "    model to\n",
            "    the model\n",
            "    hub after\n",
            "    training.\n",
            "    (default:\n",
            "    False)\n",
            "  --resume_from_checkpoint RESUME_FROM_CHECKPOINT\n",
            "    The path to\n",
            "    a folder\n",
            "    with a\n",
            "    valid\n",
            "    checkpoint\n",
            "    for your\n",
            "    model.\n",
            "    (default:\n",
            "    None)\n",
            "  --hub_model_id HUB_MODEL_ID\n",
            "    The name of\n",
            "    the\n",
            "    repository\n",
            "    to keep in\n",
            "    sync with\n",
            "    the local `\n",
            "    output_dir`\n",
            "    . (default:\n",
            "    None)\n",
            "  --hub_strategy {end,every_save,checkpoint,all_checkpoints}\n",
            "    The hub\n",
            "    strategy to\n",
            "    use when `-\n",
            "    -push_to_hu\n",
            "    b` is\n",
            "    activated.\n",
            "    (default:\n",
            "    every_save)\n",
            "  --hub_token HUB_TOKEN\n",
            "    The token\n",
            "    to use to\n",
            "    push to the\n",
            "    Model Hub.\n",
            "    (default:\n",
            "    None)\n",
            "  --hub_private_repo [HUB_PRIVATE_REPO]\n",
            "    Whether the\n",
            "    model\n",
            "    repository\n",
            "    is private\n",
            "    or not.\n",
            "    (default:\n",
            "    False)\n",
            "  --gradient_checkpointing [GRADIENT_CHECKPOINTING]\n",
            "    If True,\n",
            "    use\n",
            "    gradient ch\n",
            "    eckpointing\n",
            "    to save\n",
            "    memory at\n",
            "    the expense\n",
            "    of slower\n",
            "    backward\n",
            "    pass.\n",
            "    (default:\n",
            "    False)\n",
            "  --include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]\n",
            "    Whether or\n",
            "    not the\n",
            "    inputs will\n",
            "    be passed\n",
            "    to the `com\n",
            "    pute_metric\n",
            "    s`\n",
            "    function.\n",
            "    (default:\n",
            "    False)\n",
            "  --fp16_backend {auto,cuda_amp,apex,cpu_amp}\n",
            "    Deprecated.\n",
            "    Use half_pr\n",
            "    ecision_bac\n",
            "    kend\n",
            "    instead\n",
            "    (default:\n",
            "    auto)\n",
            "  --push_to_hub_model_id PUSH_TO_HUB_MODEL_ID\n",
            "    The name of\n",
            "    the\n",
            "    repository\n",
            "    to which\n",
            "    push the\n",
            "    `Trainer`.\n",
            "    (default:\n",
            "    None)\n",
            "  --push_to_hub_organization PUSH_TO_HUB_ORGANIZATION\n",
            "    The name of\n",
            "    the organiz\n",
            "    ation in\n",
            "    with to\n",
            "    which push\n",
            "    the\n",
            "    `Trainer`.\n",
            "    (default:\n",
            "    None)\n",
            "  --push_to_hub_token PUSH_TO_HUB_TOKEN\n",
            "    The token\n",
            "    to use to\n",
            "    push to the\n",
            "    Model Hub.\n",
            "    (default:\n",
            "    None)\n",
            "  --mp_parameters MP_PARAMETERS\n",
            "    Used by the\n",
            "    SageMaker\n",
            "    launcher to\n",
            "    send mp-\n",
            "    specific\n",
            "    args.\n",
            "    Ignored in\n",
            "    Trainer\n",
            "    (default: )\n",
            "  --auto_find_batch_size [AUTO_FIND_BATCH_SIZE]\n",
            "    Whether to \n",
            "    automatical\n",
            "    ly decrease\n",
            "    the batch\n",
            "    size in\n",
            "    half and\n",
            "    rerun the\n",
            "    training\n",
            "    loop again\n",
            "    each time a\n",
            "    CUDA Out-\n",
            "    of-Memory\n",
            "    was reached\n",
            "    (default:\n",
            "    False)\n",
            "  --full_determinism [FULL_DETERMINISM]\n",
            "    Whether to\n",
            "    call enable\n",
            "    _full_deter\n",
            "    minism\n",
            "    instead of\n",
            "    set_seed\n",
            "    for reprodu\n",
            "    cibility in\n",
            "    distributed\n",
            "    training\n",
            "    (default:\n",
            "    False)\n",
            "  --torchdynamo {eager,nvfuser,fx2trt,fx2trt-fp16}\n",
            "    Sets up the\n",
            "    backend\n",
            "    compiler\n",
            "    for TorchDy\n",
            "    namo.\n",
            "    TorchDynamo\n",
            "    is a Python\n",
            "    level JIT\n",
            "    compiler\n",
            "    designed to\n",
            "    make\n",
            "    unmodified\n",
            "    PyTorch\n",
            "    programs\n",
            "    faster.\n",
            "    TorchDynamo\n",
            "    dynamically\n",
            "    modifies\n",
            "    the Python\n",
            "    bytecode\n",
            "    right\n",
            "    before its\n",
            "    executed.\n",
            "    It rewrites\n",
            "    Python\n",
            "    bytecode to\n",
            "    extract\n",
            "    sequences\n",
            "    of PyTorch\n",
            "    operations\n",
            "    and lifts\n",
            "    them up\n",
            "    into Fx\n",
            "    graph. We\n",
            "    can then\n",
            "    pass these\n",
            "    Fx graphs\n",
            "    to other\n",
            "    backend\n",
            "    compilers.\n",
            "    There are\n",
            "    two options\n",
            "    - eager and\n",
            "    nvfuser.\n",
            "    Eager\n",
            "    defaults to\n",
            "    pytorch\n",
            "    eager and\n",
            "    is useful\n",
            "    for\n",
            "    debugging.\n",
            "    nvfuser\n",
            "    path uses\n",
            "    AOT\n",
            "    Autograd\n",
            "    and nvfuser\n",
            "    compiler to\n",
            "    optimize\n",
            "    the models.\n",
            "    (default:\n",
            "    None)\n",
            "  --ray_scope RAY_SCOPE\n",
            "    The scope\n",
            "    to use when\n",
            "    doing hyper\n",
            "    parameter\n",
            "    search with\n",
            "    Ray. By\n",
            "    default,\n",
            "    `\"last\"`\n",
            "    will be\n",
            "    used. Ray\n",
            "    will then\n",
            "    use the\n",
            "    last\n",
            "    checkpoint\n",
            "    of all\n",
            "    trials,\n",
            "    compare\n",
            "    those, and\n",
            "    select the\n",
            "    best one.\n",
            "    However,\n",
            "    other\n",
            "    options are\n",
            "    also\n",
            "    available.\n",
            "    See the Ray\n",
            "    documentati\n",
            "    on (https:/\n",
            "    /docs.ray.i\n",
            "    o/en/latest\n",
            "    /tune/api_d\n",
            "    ocs/analysi\n",
            "    s.html#ray.\n",
            "    tune.Experi\n",
            "    mentAnalysi\n",
            "    s.get_best_\n",
            "    trial) for\n",
            "    more\n",
            "    options.\n",
            "    (default:\n",
            "    last)\n",
            "  --ddp_timeout DDP_TIMEOUT\n",
            "    Overrides\n",
            "    the default\n",
            "    timeout for\n",
            "    distributed\n",
            "    training\n",
            "    (value\n",
            "    should be\n",
            "    given in\n",
            "    seconds).\n",
            "    (default:\n",
            "    1800)\n",
            "  --distill_teacher DISTILL_TEACHER\n",
            "    Teacher\n",
            "    model (a\n",
            "    trained\n",
            "    text classi\n",
            "    fication\n",
            "    model)\n",
            "    (default:\n",
            "    None)\n",
            "  --best_model_after_epoch BEST_MODEL_AFTER_EPOCH\n",
            "    Epoch after\n",
            "    which best\n",
            "    model will\n",
            "    be saved.\n",
            "    (default:\n",
            "    None)\n",
            "  --recipe RECIPE\n",
            "    Path to a\n",
            "    SparseML sp\n",
            "    arsificatio\n",
            "    n recipe,\n",
            "    see https:/\n",
            "    /github.com\n",
            "    /neuralmagi\n",
            "    c/sparseml\n",
            "    for more\n",
            "    information\n",
            "    (default:\n",
            "    None)\n",
            "  --recipe_args RECIPE_ARGS\n",
            "    Recipe\n",
            "    arguments\n",
            "    to be\n",
            "    overwritten\n",
            "    (default:\n",
            "    None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sparse Transfer Learning with SST2**\n",
        "\n",
        "SparseML's CLI enables you to kick-off training workflows with various utilities like dataset loading, checkpoint saving, \n",
        "metric reporting, and logging handled for you. All we have to do is pass a `model_name_or_path` (the starting checkpoint), a `task` (the GLUE task to train on), and a `recipe` (a YAML file specifying the sparsity related parameters) and we are up and running. The `recipes` is critical for instructing the training script how to modify the training process with sparsity related algorithms. For Sparse Transfer Learning, we will use a `recipe` that instructs SparseML to maintain sparsity during the training process and to apply quantization over the final few epochs. "
      ],
      "metadata": {
        "id": "vG_qKQcXsfgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run Transfer Learning**\n",
        "\n",
        "For SST2, there is a pre-made transfer learning recipe available in [SparseZoo](https://sparsezoo.neuralmagic.com/models/nlp%2Fsentiment_analysis%2Fobert-base%2Fpytorch%2Fhuggingface%2Fsst2%2Fpruned90_quant-none). As such, we kick off transfer learning with the following:"
      ],
      "metadata": {
        "id": "jM1QJxiMu5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.transformers.text_classification \\\n",
        "  --task_name sst2 \\\n",
        "  --model_name_or_path zoo:nlp/masked_language_modeling/obert-base/pytorch/huggingface/wikipedia_bookcorpus/pruned90-none \\\n",
        "  --recipe zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none \\\n",
        "  --distill_teacher zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/base-none \\\n",
        "  --output_dir sparse_quantized_bert-text_classification_sst2 \\\n",
        "  --max_seq_length 128 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --preprocessing_num_workers 6 \\\n",
        "  --do_train --do_eval --evaluation_strategy epoch --fp16 --save_strategy epoch --save_total_limit 1"
      ],
      "metadata": {
        "id": "hz8o5CNlsNo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's discuss the key arguments:\n",
        "- `--task_name sst2` instructs SparseML to download and fine-tune onto the SST2 dataset. You can pass any GLUE task as the task name and SparseML automatically downloads the dataset from the Hugging Face hub.\n",
        "\n",
        "- `--model_name_or_path zoo:nlp/masked_language_modeling/obert-base/pytorch/huggingface/wikipedia_bookcorpus/pruned90-none` specifies the starting checkpoint for the fine tuning. Here, we passed a SparseZoo stub identifying the 90% pruned version of BERT trained with masked language modeling on the Wikipedia and BookCorpus datasets. SparseML downloads the checkpoint from the Zoo when the script starts.\n",
        "\n",
        "- `--recipe zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none` specifies the recipe to be applied by SparseML. Here, we passed a SparseZoo stub identifying the transfer learning recipe for the SST2 dataset. SparseML downloads the recipe from the Zoo when the script starts. See below for the details of what this recipe looks like.\n",
        "\n",
        "- `--distill_teacher zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/base-none` is an optional argument that specifies a model to use for as a teacher to apply distillation during the training process. We passed a SparseZoo stub identifying a dense BERT model trained on SST2. SparseML downloads the teacher from the Zoo when the script starts.\n",
        "\n",
        "The script downloads the starting checkpoint, the teacher model, and transfer learning recipe from SparseZoo as well as the SST2 \n",
        "dataset and trains the model for 13 epochs, converging to ~92% accuracy on the validation set. The final model is quantized \n",
        "with 90% of weights pruned!"
      ],
      "metadata": {
        "id": "-HFYMN3yq6fJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Transfer Learning Recipe**\n",
        "\n",
        "Here's what the transfer learning recipe for the SST2 dataset looks like.\n",
        "\n",
        "The \"Modifiers\" are the important items that encode how SparseML should modify the training process for Sparse Transfer Learning:\n",
        "- `ConstantPruningModifier` tells SparseML to pin weights at 0 over all epochs, maintaining the sparsity structure of the network\n",
        "- `QuantizationModifier` tells SparseML to quanitze the weights with quantization aware training over the last 5 epochs\n",
        "- `DistillationModifier` tells SparseML how to apply distillation to the model, including the layer and some hyperparameters\n",
        "\n",
        "SparseML parses the modifiers and updates the training process to implement the algorithms and hyperparameters specified in the recipes."
      ],
      "metadata": {
        "id": "ZJnGKuXnwhWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparsezoo import Model\n",
        "transfer_stub = \"zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none\"\n",
        "download_dir = \"./transfer_recipe\"\n",
        "zoo_model = Model(transfer_stub, download_path=download_dir)\n",
        "recipe_path = zoo_model.recipes.default.path\n",
        "print(recipe_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Z_a3HOwrpu",
        "outputId": "e7babee2-c8ef-49e3-c46c-7622b6c6f187"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./transfer_recipe/recipe/recipe_original.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat ./transfer_recipe/recipe/recipe_original.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oeu1PvyYxR0V",
        "outputId": "66247d7a-aee9-4413-b014-33ebd7b7c637"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!--\n",
            "Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "you may not use this file except in compliance with the License.\n",
            "You may obtain a copy of the License at\n",
            "\n",
            "   http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing,\n",
            "software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "See the License for the specific language governing permissions and\n",
            "limitations under the License.\n",
            "-->\n",
            "\n",
            "---\n",
            "\n",
            "version: 1.1.0\n",
            "\n",
            "# General Variables\n",
            "num_epochs: &num_epochs 13\n",
            "init_lr: 1.5e-4\n",
            "final_lr: 0\n",
            "\n",
            "qat_start_epoch: &qat_start_epoch 8.0\n",
            "observer_epoch: &observer_epoch 12.0\n",
            "quantize_embeddings: &quantize_embeddings 1\n",
            "\n",
            "distill_hardness: &distill_hardness 1.0\n",
            "distill_temperature: &distill_temperature 2.0\n",
            "\n",
            "weight_decay: 0.01\n",
            "\n",
            "# Modifiers:\n",
            "\n",
            "training_modifiers:\n",
            "  - !EpochRangeModifier\n",
            "      end_epoch: eval(num_epochs)\n",
            "      start_epoch: 0.0\n",
            "\n",
            "  - !LearningRateFunctionModifier\n",
            "      start_epoch: 0\n",
            "      end_epoch: eval(num_epochs)\n",
            "      lr_func: linear\n",
            "      init_lr: eval(init_lr)\n",
            "      final_lr: eval(final_lr)\n",
            "\n",
            "quantization_modifiers:\n",
            "\n",
            "  - !QuantizationModifier\n",
            "      start_epoch: eval(qat_start_epoch)\n",
            "      disable_quantization_observer_epoch: eval(observer_epoch)\n",
            "      freeze_bn_stats_epoch: eval(observer_epoch)\n",
            "      quantize_embeddings: eval(quantize_embeddings)\n",
            "      quantize_linear_activations: 0\n",
            "      exclude_module_types: ['LayerNorm', 'Tanh']\n",
            "      submodules:\n",
            "        - bert.embeddings\n",
            "        - bert.encoder\n",
            "        - bert.pooler\n",
            "        - classifier\n",
            "\n",
            "\n",
            "distillation_modifiers:\n",
            "  - !DistillationModifier\n",
            "     hardness: eval(distill_hardness)\n",
            "     temperature: eval(distill_temperature)\n",
            "     distill_output_keys: [logits]\n",
            "\n",
            "constant_modifiers:\n",
            "\n",
            "  - !ConstantPruningModifier\n",
            "      start_epoch: 0.0\n",
            "      params: __ALL_PRUNABLE__\n",
            "\n",
            "regularization_modifiers:\n",
            "\n",
            "  - !SetWeightDecayModifier\n",
            "      start_epoch: 0.0\n",
            "      weight_decay: eval(weight_decay)\n",
            "---\n",
            "\n",
            "# oBERT Sparse Transfer and Quantization Recipe - Sentiment Analysis with SST-2\n",
            "\n",
            "This recipe defines the hyperparams necessary to transfer and quantize the oBERT pruned 90% to sentiment analysis tasks [SST-2 (Standford Sentiment Treebank)](https://nlp.stanford.edu/sentiment/).\n",
            "Users are encouraged to experiment with the training length and initial learning rate to either expedite training or to produce a more accurate model.\n",
            "This can be done by either editing the recipe or supplying the --recipe_args argument to the training commands.\n",
            "For example, the following appended to the training commands will change the number of epochs and the initial learning rate:\n",
            "```bash\n",
            "--recipe_args '{\"num_epochs\":8,\"init_lr\":0.0001}'\n",
            "```\n",
            "\n",
            "## Training\n",
            "\n",
            "To set up the training environment, [install SparseML](https://github.com/neuralmagic/sparseml#installation).\n",
            "\n",
            "### SST-2 (Sentiment Analysis)\n",
            "\n",
            "The following command is used to transfer to the SST-2 sentiment analysis task in the training environment on a single GPU.\n",
            "It achieves 91.97% accuracy on the validation set.\n",
            "\n",
            "```bash\n",
            "sparseml.transformers.train.text_classification \\\n",
            "  --output_dir sparse_quantized_bert-text_classification_sst2 \\\n",
            "  --model_name_or_path zoo:nlp/masked_language_modeling/obert-base/pytorch/huggingface/wikipedia_bookcorpus/pruned90-none \\\n",
            "  --recipe zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none \\\n",
            "  --distill_teacher zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/base-none \\\n",
            "  --task_name sst2 --max_seq_length 128 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --preprocessing_num_workers 6 \\\n",
            "  --do_train --do_eval --evaluation_strategy epoch --fp16  \\\n",
            "  --save_strategy epoch --save_total_limit 1\n",
            "```\n",
            "\n",
            "## Evaluation\n",
            "\n",
            "The model could be evaluated with the following command:\n",
            "\n",
            "\n",
            "```bash\n",
            "sparseml.transformers.train.text_classification \\\n",
            "  --output_dir sparse_quantized_bert-text_classification_sst2 \\\n",
            "  --model_name_or_path zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none \\\n",
            "  --task_name sst2 --max_seq_length 128 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --preprocessing_num_workers 6 \\\n",
            "  --do_eval \n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Export to ONNX**\n",
        "\n",
        "Once you have trained your model, export to ONNX in order to deploy with DeepSparse. The artifacts of the training process \n",
        "are saved to your local filesystem. \n",
        "\n",
        "Run the following to convert your PyTorch checkpoint to ONNX:"
      ],
      "metadata": {
        "id": "bFbppO99xGeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.transformers.export_onnx \\\n",
        "  --model_path sparse_quantized_bert-text_classification_sst2 \\\n",
        "  --task text_classification"
      ],
      "metadata": {
        "id": "OHKEUvPOx-su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script above creates a `deployment` folder in your local directory, which has all of the files needed for deployment with DeepSparse including the `model.onnx`, `config.json`, and `tokenizer.json` files."
      ],
      "metadata": {
        "id": "B3JKl3xIyDIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sparse Transfer Learning with a Custom Dataset**\n",
        "\n",
        "Beyond the built-in GLUE tasks, we can also use a dataset from the Hugging Face Hub or pass via local files. Let's try an example of each for the sentiment analysis using [Rotten Tomatoes Dataset](https://huggingface.co/datasets/rotten_tomatoes), which containing 5,331 positive and 5,331 negative processed sentences.\n",
        "\n",
        "For simplicity, we will perform the fine-tuning without distillation. Although the transfer learning recipe contains distillation\n",
        "modifiers, by setting `--distill_teacher disable` we instruct SparseML to skip distillation."
      ],
      "metadata": {
        "id": "bCE4HKWvyWRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using a Hugging Face Dataset**\n",
        "\n",
        "Let's walk through how to pass a Hugging Face dataset identifier to the CLI."
      ],
      "metadata": {
        "id": "n5ab0yh6yspE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Inspecting Rotten Tomatoes Dataset**"
      ],
      "metadata": {
        "id": "Q41afk_22DcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "rotten_tomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "print(rotten_tomatoes)\n",
        "pprint(rotten_tomatoes[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "566293ac880847c881b31156a3e23058",
            "9ad6f71025b641e2b3fb2d09828a599f",
            "fb018ff11e5a4cedb2c24a530dc35051",
            "b02c170e03a141739d9a5829a198a0fd",
            "0fe3690ffec348648cd9f117fa5c3210",
            "a1ba58f4af1c448c893a505bb9d49dc5",
            "9c4f62cfcc0b40548aba00fb89db60c1",
            "afded944c3e04103b23f7c00f71ed3ea",
            "3c9d7e2e19094655bfbf9ff883b95d5c",
            "3be6cc4d76804eedb7f083ab25954b93",
            "8d506e4db2ef432bb2a8cd52b002c374",
            "476cb165e0e4498f844a5de0c18ee260",
            "e046ccabb9f5456cbd13bdbb8351906d",
            "d8903ec810be4cfa933101b1de8d63a5",
            "1f62b91c48e2479aac69c6dbe658d3f6",
            "d8a47aabb4734fc28867ab20d9cde6fb",
            "283c1e3d22ab4bc6815183334c01969c",
            "c9595d6efa2a4241bae1e4f4847e12f2",
            "3d5313565f964b59a379dccaa5ec6e65",
            "e879a1b65e4f48fea29e0daac81584b8",
            "dae024ecf2a34a54baac6de933ef98bd",
            "ab066ac13ae149f5ac184296afbfb99d",
            "77c8b25265bd4df9b58a4cb034017d3f",
            "b802a594e02c40bfa7defa75da263cf1",
            "211113ed758348f2a3ea84a0eeb42556",
            "668611a1b4124579a0d19e412525b6fb",
            "1adb4b370f434a67afe28a0e5a17e68c",
            "d50676f380e64591a908375083267a24",
            "613db94f4de44b4fb9997b8447ff562e",
            "bfba9ab7c49d478dac3c693c186df0cd",
            "ca3576bdd4424528bc8d9c0ea9b19b3c",
            "b8551aee7bb4413bb5bbad8cb52a5286",
            "4bb09069a695422cb8acd7dcc74b94c4",
            "5426133a767b49558aadf8031acce26f",
            "49c6fb16291146568b8280a4e6cf656e",
            "46d0818f4e924c368d768490da969f38",
            "f732e5ae996844cb9a9bf7045bec6baa",
            "f9d4bf2a0de34ca6b25fdb42be79aad9",
            "bf72d02194344d42b26ee334380c33a2",
            "997d916785df424382e9b0b3a16a0937",
            "04346244975e4f5e9009deb3562246ef",
            "6e3ed829b7374b2bbe0e3a87d5ecdb87",
            "d4401fb79a9a4b3bb597226da22fc0e4",
            "6a30cb870be941169aaaf3217faaa70a",
            "d56ce514bc5649c398a6d81a6bafb0aa",
            "7db6ca3a6c2e4bccb65a2eebff5412ef",
            "42de41b7b4e443f399add54a0fdb7403",
            "4d58cd5c68d6432091719b734c4cdc2c",
            "e30c9080e3d24f27a2a108d0f36adb9e",
            "51aaed1f169147cca061d9fcca9ed8a0",
            "4417b06b81f94cd19d718b3e306602be",
            "72ac381d438e4686bc14aa636bc83cdf",
            "28c7b41b06bf4520a6b57ffdb6cf7f4b",
            "ab76c15a18d647c9b68ebf71e32c19c1",
            "a33cd277de2c4fa5ba82e7258073b361",
            "5734587799344996b0f84002f36e97b0",
            "f2becc1379694010922ec61d24740de5",
            "233d5c00e05b4fb3bac275a60ed1dd75",
            "c77e529607364c07bb9466470ddb757b",
            "fe75483260134b60bfd5e2083409748c",
            "3cde3ab5088a408d8ee44fc2b66b1dd3",
            "03be1f136fbb4848b9eeb70b6d79e46d",
            "acc00d27cc7641528b171fa8d69bf0d3",
            "92633305bf00461cae9f9ca3757d626d",
            "d76708c01aa94a56bcc03ac8b8f5d149",
            "a675ba9b703a4cf39afb1da981abf89b",
            "95e6c845dcc24aad991e35d1931aff5d",
            "f581feff3951424abd982d26eeb987a8",
            "3c6d873f7a7d46d39751febc963dd8e8",
            "4de5e9ec702a43e391c2bffec8c57d08",
            "cdedb9db9b274b8a9dcc705c4c01ef72",
            "213c5b0c334d45608e6688dc400b24ec",
            "9db54ccf8be242ff86566c13b88cb98b",
            "79d2f71c08fe4c39b02bbc357970dbdc",
            "d9d91fe0dde842aa9e5b5be803ab0d95",
            "45c7f47fb840435b8cf833d2ca2c65b0",
            "508f4cdd142a4958bc6abcf58926b59d"
          ]
        },
        "id": "hfKp5RaMybmt",
        "outputId": "7c46a734-582a-4e39-91c6-b692d7ffff2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "566293ac880847c881b31156a3e23058"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "476cb165e0e4498f844a5de0c18ee260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset rotten_tomatoes_movie_review/default (download: 476.34 KiB, generated: 1.28 MiB, post-processed: Unknown size, total: 1.75 MiB) to /root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/488k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c8b25265bd4df9b58a4cb034017d3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5426133a767b49558aadf8031acce26f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d56ce514bc5649c398a6d81a6bafb0aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5734587799344996b0f84002f36e97b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset rotten_tomatoes_movie_review downloaded and prepared to /root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95e6c845dcc24aad991e35d1931aff5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 8530\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "})\n",
            "{'label': 1,\n",
            " 'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and '\n",
            "         \"that he's going to make a splash even greater than arnold \"\n",
            "         'schwarzenegger , jean-claud van damme or steven segal .'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Kick off Training**\n",
        "\n",
        "To use this dataset with the CLI, we can replace the `--task_name sst2` argument with `--dataset_name rotten_tomatoes --input_column_names text --label_column_name label`. SparseML will then download the dataset from the Hugging Face hub and run training as before."
      ],
      "metadata": {
        "id": "pdpvTT654LAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.transformers.text_classification \\\n",
        "  --model_name_or_path zoo:nlp/masked_language_modeling/obert-base/pytorch/huggingface/wikipedia_bookcorpus/pruned90-none \\\n",
        "  --recipe zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none \\\n",
        "  --recipe_args '{\"num_epochs\":12,\"qat_start_epoch\":7.0, \"observer_epoch\": 11.0}' \\\n",
        "  --distill_teacher disable \\\n",
        "  --dataset_name rotten_tomatoes --input_column_names \"text\" --label_column_name \"label\" \\\n",
        "  --output_dir sparse_quantized_bert-text_classification_rotten_tomatoes-hf_dataset --max_seq_length 128 --per_device_train_batch_size 32 \\\n",
        "  --per_device_eval_batch_size 32 --preprocessing_num_workers 6 --do_train --do_eval --evaluation_strategy epoch --fp16  \\\n",
        "  --save_strategy epoch --save_total_limit 1"
      ],
      "metadata": {
        "id": "GMxgkhMRz-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will notice that we used the same recipe as we did in the SST2 case (identified by the SparseZoo stub `zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none`). Since the Rotten Tomatoes and SST2 tasks are similiar, we chose to start with the same hyperparameters as we used in SST2 training.\n",
        "\n",
        "\n",
        "To update a recipe, you can download the YAML file from SparseZoo, make updates to the YAML directly, and pass the local path to SparseML. In this case, we used `--recipe_args '{\"num_epochs\":12,\"qat_start_epoch\":7.0, \"observer_epoch\": 11.0}'` to modify a recipe on the fly, updating to only run for 11 epochs."
      ],
      "metadata": {
        "id": "7NfB9uhi0CBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using Local CSV/JSON Files**\n",
        "\n",
        "Let's walk through how to pass a CSV/JSON dataset to the CLI."
      ],
      "metadata": {
        "id": "79KVF5TB11xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save Dataset as a CSV File**\n",
        "\n",
        "For this example, we use Hugging Face `datasets` to create a CSV file for Rotten Tomatoes that can be passed to SparseML's CLI but you can use any framework you want to create the CSV."
      ],
      "metadata": {
        "id": "eZF7myQc23uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "rotten_tomatoes = load_dataset(\"rotten_tomatoes\")\n",
        "print(rotten_tomatoes)\n",
        "pprint(rotten_tomatoes[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "115c1fe4c88e49f8a5f7a9b08e756a1c",
            "2ca501ae02d74e4ea9fc2bba9a67c673",
            "9d8e7c853bf144eaba44000f60b5c175",
            "441568c8a77d4574bca4b570e5967293",
            "4458b488ab794c0b9b52d90b3028f627",
            "95ac3f6d80de4be2a6bf92da4222b51f",
            "79b4deed99b6446994180b85d6bdf1cf",
            "8b1d8a4b4e024ee684032b7109e7d967",
            "98233e3f890c4be7bff265b1dfdd7abf",
            "3626b2df8aac4feea331442f712c7f70",
            "315cb39123814033859d576caafbfcdf"
          ]
        },
        "id": "zWsAD8b_2tQ2",
        "outputId": "187fdaaf-49a8-4df0-9cfa-f8d86ec4f584"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset rotten_tomatoes_movie_review (/root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "115c1fe4c88e49f8a5f7a9b08e756a1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 8530\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "})\n",
            "{'label': 1,\n",
            " 'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and '\n",
            "         \"that he's going to make a splash even greater than arnold \"\n",
            "         'schwarzenegger , jean-claud van damme or steven segal .'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rotten_tomatoes[\"train\"].to_csv(\"./rotten_tomatoes-train.csv\")\n",
        "rotten_tomatoes[\"validation\"].to_csv(\"./rotten_tomatoes-validation.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "197363819ce94edd988f026e56a67326",
            "4eed2def147540de8135ceb93c077952",
            "f0c4ab1249e24040a3e87d2ef08a3a2f",
            "6f0eed9f129f47ce9d5196a392e54f27",
            "f64e467c48aa4314b8cd9b256c58f3ba",
            "c8811b76169b48cea328354b1952d9aa",
            "b662d86d9e894d7c83550894d88c2f17",
            "241496d6391b4242ab90490d5a9d2e9b",
            "ba411ee74b504aa991e0ddb2bd421728",
            "16723d41863f4433bdf436d8e34ac3c8",
            "4285c3c49dbb404b82865fe700de22ee",
            "1dde9c154d1b4a3a9609bb741ee8be5b",
            "1fbd0c17e02941c1878896e250b4aa80",
            "6375ddde788140ab9b30e50b7396ad7a",
            "51a1e28ea0db4555b73376578b16e5d4",
            "a6adf99498f44730bc89ab2fdff65716",
            "82c9b12a90be4da6b2284754561c5105",
            "98903170d7b944158860b9acf7ee82a3",
            "f27b78522e494462a4a7ac95f6701af9",
            "b9bb8144b5b74ffcb9eb03330e215f67",
            "8d33ba66e2ef4e1a93fb9576aa68d38b",
            "30dcae33cc2e41dc8194f5787de1991b"
          ]
        },
        "id": "CTwUYc913uDB",
        "outputId": "0e08bbc9-087f-40c3-ee3b-67c2fc1f7814"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "197363819ce94edd988f026e56a67326"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dde9c154d1b4a3a9609bb741ee8be5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130634"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the data is a CSV file with text and label as the columns:"
      ],
      "metadata": {
        "id": "C5O2haE73_my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head ./rotten_tomatoes-train.csv --lines=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2kMBxV134ii",
        "outputId": "9fd2abe1-4967-4fe4-cdbe-5f2bc32a18ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",text,label\n",
            "0,\"the rock is destined to be the 21st century's new \"\" conan \"\" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",1\n",
            "1,\"the gorgeously elaborate continuation of \"\" the lord of the rings \"\" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\",1\n",
            "2,effective but too-tepid biopic,1\n",
            "3,\"if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\",1\n",
            "4,\"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\",1\n",
            "5,the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .,1\n",
            "6,offers that rare combination of entertainment and education .,1\n",
            "7,perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .,1\n",
            "8,steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .,1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head ./rotten_tomatoes-validation.csv --lines=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JdeJqQC3-SE",
        "outputId": "487f797a-94fb-49c1-b3e4-781843c32a50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",text,label\n",
            "0,compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .,1\n",
            "1,the soundtrack alone is worth the price of admission .,1\n",
            "2,rodriguez does a splendid job of racial profiling hollywood style--casting excellent latin actors of all ages--a trend long overdue .,1\n",
            "3,\"beneath the film's obvious determination to shock at any cost lies considerable skill and determination , backed by sheer nerve .\",1\n",
            "4,bielinsky is a filmmaker of impressive talent .,1\n",
            "5,\"so beautifully acted and directed , it's clear that washington most certainly has a new career ahead of him if he so chooses .\",1\n",
            "6,a visual spectacle full of stunning images and effects .,1\n",
            "7,a gentle and engrossing character study .,1\n",
            "8,\"it's enough to watch huppert scheming , with her small , intelligent eyes as steady as any noir villain , and to enjoy the perfectly pitched web of tension that chabrol spins .\",1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Kick off Training**\n",
        "\n",
        "To use the local files with the CLI, pass `--train_file ./rotten_tomatoes-train.csv --validation_file ./rotten_tomatoes-validation.csv  --input_column_names text --label_column_name label`.\n",
        "\n",
        "Run the following:"
      ],
      "metadata": {
        "id": "D70YemqF3_D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.transformers.text_classification \\\n",
        "  --model_name_or_path zoo:nlp/masked_language_modeling/obert-base/pytorch/huggingface/wikipedia_bookcorpus/pruned90-none \\\n",
        "  --recipe zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none \\\n",
        "  --distill_teacher disable \\\n",
        "  --train_file ./rotten_tomatoes-train.csv --validation_file ./rotten_tomatoes-validation.csv  --input_column_names text --label_column_name label \\\n",
        "  --output_dir sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset --max_seq_length 128 --per_device_train_batch_size 32 \\\n",
        "  --per_device_eval_batch_size 32 --preprocessing_num_workers 6 --do_train --do_eval --evaluation_strategy epoch --fp16  \\\n",
        "  --save_strategy epoch --save_total_limit 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDbMuS74YaP",
        "outputId": "bee4d975-cb06-464e-8008-819e1b78466a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-27 03:22:35.305202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-27 03:22:36.332674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 03:22:36.332817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 03:22:36.332841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-27 03:22:40 sparseml.transformers.text_classification WARNING  Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "WARNING:sparseml.transformers.text_classification:Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "2023-02-27 03:22:40 sparseml.transformers.text_classification INFO     Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "best_model_after_epoch=None,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "distill_teacher=disable,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/runs/Feb27_03-22-39_0aa8d232ebdf,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=32,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "recipe=zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none,\n",
            "recipe_args=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "INFO:sparseml.transformers.text_classification:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "best_model_after_epoch=None,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "distill_teacher=disable,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/runs/Feb27_03-22-39_0aa8d232ebdf,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=32,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "recipe=zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none,\n",
            "recipe_args=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "2023-02-27 03:22:40 sparseml.transformers.text_classification INFO     load a local file for train: ./rotten_tomatoes-train.csv\n",
            "INFO:sparseml.transformers.text_classification:load a local file for train: ./rotten_tomatoes-train.csv\n",
            "2023-02-27 03:22:40 sparseml.transformers.text_classification INFO     load a local file for validation: ./rotten_tomatoes-validation.csv\n",
            "INFO:sparseml.transformers.text_classification:load a local file for validation: ./rotten_tomatoes-validation.csv\n",
            "WARNING:datasets.builder:Using custom data configuration default-609eb57d53d74fb9\n",
            "INFO:datasets.builder:Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-609eb57d53d74fb9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-609eb57d53d74fb9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n",
            "100% 2/2 [00:00<00:00, 8081.51it/s]\n",
            "INFO:datasets.utils.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.utils.download_manager:Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 1877.07it/s]\n",
            "INFO:datasets.utils.info_utils:Unable to verify checksums.\n",
            "INFO:datasets.builder:Generating split train\n",
            "INFO:datasets.builder:Generating split validation\n",
            "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-609eb57d53d74fb9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 999.48it/s]\n",
            "[INFO|configuration_utils.py:651] 2023-02-27 03:22:41,792 >> loading configuration file /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training/config.json\n",
            "[INFO|configuration_utils.py:705] 2023-02-27 03:22:41,795 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"/root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2153] 2023-02-27 03:22:42,126 >> loading weights file /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:2596] 2023-02-27 03:22:43,541 >> Some weights of the model checkpoint at /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2608] 2023-02-27 03:22:43,542 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "2023-02-27 03:22:43 sparseml.transformers.utils.model INFO     Loaded student from /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training with 109483778 total params. Of those there are 85526016 prunable params which have 89.3777046740959 avg sparsity.\n",
            "INFO:sparseml.transformers.utils.model:Loaded student from /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training with 109483778 total params. Of those there are 85526016 prunable params which have 89.3777046740959 avg sparsity.\n",
            "2023-02-27 03:22:46 sparseml.transformers.utils.model INFO     sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 109483778, \"sparse\": 76441960, \"sparsity_percent\": 69.82035274668728, \"prunable\": 85526016, \"prunable_sparse\": 76441190, \"prunable_sparsity_percent\": 89.3777046740959, \"quantizable\": 85609730, \"quantized\": 0, \"quantized_percent\": 0.0}, \"params_info\": {\"bert.encoder.layer.0.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8644917607307434, \"quantized\": false}, \"bert.encoder.layer.0.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8680216670036316, \"quantized\": false}, \"bert.encoder.layer.0.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9312150478363037, \"quantized\": false}, \"bert.encoder.layer.0.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9232262372970581, \"quantized\": false}, \"bert.encoder.layer.0.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9153103232383728, \"quantized\": false}, \"bert.encoder.layer.0.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9356380105018616, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8620554804801941, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8625064492225647, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9279242753982544, \"quantized\": false}, \"bert.encoder.layer.1.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9245097041130066, \"quantized\": false}, \"bert.encoder.layer.1.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8945091962814331, \"quantized\": false}, \"bert.encoder.layer.1.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9265751242637634, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8451063632965088, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8532799482345581, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9295670986175537, \"quantized\": false}, \"bert.encoder.layer.2.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9288228154182434, \"quantized\": false}, \"bert.encoder.layer.2.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8895581364631653, \"quantized\": false}, \"bert.encoder.layer.2.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9237624406814575, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8711106777191162, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8704121708869934, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9085676670074463, \"quantized\": false}, \"bert.encoder.layer.3.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9130028486251831, \"quantized\": false}, \"bert.encoder.layer.3.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8868213295936584, \"quantized\": false}, \"bert.encoder.layer.3.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9209082126617432, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8635711669921875, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8665059208869934, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8824039101600647, \"quantized\": false}, \"bert.encoder.layer.4.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8957400918006897, \"quantized\": false}, \"bert.encoder.layer.4.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8822059631347656, \"quantized\": false}, \"bert.encoder.layer.4.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9172935485839844, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8685166835784912, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8675944209098816, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8843333125114441, \"quantized\": false}, \"bert.encoder.layer.5.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8958756923675537, \"quantized\": false}, \"bert.encoder.layer.5.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8838331699371338, \"quantized\": false}, \"bert.encoder.layer.5.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.91917884349823, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8699256181716919, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8717482089996338, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8924729824066162, \"quantized\": false}, \"bert.encoder.layer.6.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9078572392463684, \"quantized\": false}, \"bert.encoder.layer.6.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8827946782112122, \"quantized\": false}, \"bert.encoder.layer.6.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9222526550292969, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8792538046836853, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8780839443206787, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8773871660232544, \"quantized\": false}, \"bert.encoder.layer.7.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8886498212814331, \"quantized\": false}, \"bert.encoder.layer.7.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8991622924804688, \"quantized\": false}, \"bert.encoder.layer.7.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9271066188812256, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8583950400352478, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.856842041015625, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8692152500152588, \"quantized\": false}, \"bert.encoder.layer.8.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8843451738357544, \"quantized\": false}, \"bert.encoder.layer.8.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9019758701324463, \"quantized\": false}, \"bert.encoder.layer.8.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9253442287445068, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8518574833869934, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8523983359336853, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8783705234527588, \"quantized\": false}, \"bert.encoder.layer.9.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8867306113243103, \"quantized\": false}, \"bert.encoder.layer.9.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9011484980583191, \"quantized\": false}, \"bert.encoder.layer.9.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.91860032081604, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8570064902305603, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8588087558746338, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8733994960784912, \"quantized\": false}, \"bert.encoder.layer.10.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8768836259841919, \"quantized\": false}, \"bert.encoder.layer.10.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9072990417480469, \"quantized\": false}, \"bert.encoder.layer.10.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9249801635742188, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8541886806488037, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8596123456954956, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8792198896408081, \"quantized\": false}, \"bert.encoder.layer.11.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8855014443397522, \"quantized\": false}, \"bert.encoder.layer.11.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8986706137657166, \"quantized\": false}, \"bert.encoder.layer.11.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9309417009353638, \"quantized\": false}, \"bert.pooler.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.0, \"quantized\": false}, \"classifier.weight\": {\"numel\": 1536, \"sparsity\": 0.0, \"quantized\": false}}}\n",
            "INFO:sparseml.transformers.utils.model:sparse model detected, all sparsification info: {\"params_summary\": {\"total\": 109483778, \"sparse\": 76441960, \"sparsity_percent\": 69.82035274668728, \"prunable\": 85526016, \"prunable_sparse\": 76441190, \"prunable_sparsity_percent\": 89.3777046740959, \"quantizable\": 85609730, \"quantized\": 0, \"quantized_percent\": 0.0}, \"params_info\": {\"bert.encoder.layer.0.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8644917607307434, \"quantized\": false}, \"bert.encoder.layer.0.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8680216670036316, \"quantized\": false}, \"bert.encoder.layer.0.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9312150478363037, \"quantized\": false}, \"bert.encoder.layer.0.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9232262372970581, \"quantized\": false}, \"bert.encoder.layer.0.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9153103232383728, \"quantized\": false}, \"bert.encoder.layer.0.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9356380105018616, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8620554804801941, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8625064492225647, \"quantized\": false}, \"bert.encoder.layer.1.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9279242753982544, \"quantized\": false}, \"bert.encoder.layer.1.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9245097041130066, \"quantized\": false}, \"bert.encoder.layer.1.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8945091962814331, \"quantized\": false}, \"bert.encoder.layer.1.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9265751242637634, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8451063632965088, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8532799482345581, \"quantized\": false}, \"bert.encoder.layer.2.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9295670986175537, \"quantized\": false}, \"bert.encoder.layer.2.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9288228154182434, \"quantized\": false}, \"bert.encoder.layer.2.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8895581364631653, \"quantized\": false}, \"bert.encoder.layer.2.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9237624406814575, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8711106777191162, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8704121708869934, \"quantized\": false}, \"bert.encoder.layer.3.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.9085676670074463, \"quantized\": false}, \"bert.encoder.layer.3.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9130028486251831, \"quantized\": false}, \"bert.encoder.layer.3.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8868213295936584, \"quantized\": false}, \"bert.encoder.layer.3.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9209082126617432, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8635711669921875, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8665059208869934, \"quantized\": false}, \"bert.encoder.layer.4.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8824039101600647, \"quantized\": false}, \"bert.encoder.layer.4.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8957400918006897, \"quantized\": false}, \"bert.encoder.layer.4.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8822059631347656, \"quantized\": false}, \"bert.encoder.layer.4.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9172935485839844, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8685166835784912, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8675944209098816, \"quantized\": false}, \"bert.encoder.layer.5.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8843333125114441, \"quantized\": false}, \"bert.encoder.layer.5.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8958756923675537, \"quantized\": false}, \"bert.encoder.layer.5.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8838331699371338, \"quantized\": false}, \"bert.encoder.layer.5.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.91917884349823, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8699256181716919, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8717482089996338, \"quantized\": false}, \"bert.encoder.layer.6.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8924729824066162, \"quantized\": false}, \"bert.encoder.layer.6.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.9078572392463684, \"quantized\": false}, \"bert.encoder.layer.6.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8827946782112122, \"quantized\": false}, \"bert.encoder.layer.6.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9222526550292969, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8792538046836853, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8780839443206787, \"quantized\": false}, \"bert.encoder.layer.7.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8773871660232544, \"quantized\": false}, \"bert.encoder.layer.7.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8886498212814331, \"quantized\": false}, \"bert.encoder.layer.7.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8991622924804688, \"quantized\": false}, \"bert.encoder.layer.7.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9271066188812256, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8583950400352478, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.856842041015625, \"quantized\": false}, \"bert.encoder.layer.8.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8692152500152588, \"quantized\": false}, \"bert.encoder.layer.8.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8843451738357544, \"quantized\": false}, \"bert.encoder.layer.8.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9019758701324463, \"quantized\": false}, \"bert.encoder.layer.8.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9253442287445068, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8518574833869934, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8523983359336853, \"quantized\": false}, \"bert.encoder.layer.9.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8783705234527588, \"quantized\": false}, \"bert.encoder.layer.9.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8867306113243103, \"quantized\": false}, \"bert.encoder.layer.9.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9011484980583191, \"quantized\": false}, \"bert.encoder.layer.9.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.91860032081604, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8570064902305603, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8588087558746338, \"quantized\": false}, \"bert.encoder.layer.10.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8733994960784912, \"quantized\": false}, \"bert.encoder.layer.10.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8768836259841919, \"quantized\": false}, \"bert.encoder.layer.10.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9072990417480469, \"quantized\": false}, \"bert.encoder.layer.10.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9249801635742188, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.query.weight\": {\"numel\": 589824, \"sparsity\": 0.8541886806488037, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.key.weight\": {\"numel\": 589824, \"sparsity\": 0.8596123456954956, \"quantized\": false}, \"bert.encoder.layer.11.attention.self.value.weight\": {\"numel\": 589824, \"sparsity\": 0.8792198896408081, \"quantized\": false}, \"bert.encoder.layer.11.attention.output.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.8855014443397522, \"quantized\": false}, \"bert.encoder.layer.11.intermediate.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.8986706137657166, \"quantized\": false}, \"bert.encoder.layer.11.output.dense.weight\": {\"numel\": 2359296, \"sparsity\": 0.9309417009353638, \"quantized\": false}, \"bert.pooler.dense.weight\": {\"numel\": 589824, \"sparsity\": 0.0, \"quantized\": false}, \"classifier.weight\": {\"numel\": 1536, \"sparsity\": 0.0, \"quantized\": false}}}\n",
            "[INFO|configuration_utils.py:651] 2023-02-27 03:22:46,240 >> loading configuration file /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training/config.json\n",
            "[INFO|configuration_utils.py:705] 2023-02-27 03:22:46,241 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"/root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1771] 2023-02-27 03:22:46,242 >> loading file vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1771] 2023-02-27 03:22:46,242 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1771] 2023-02-27 03:22:46,242 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1771] 2023-02-27 03:22:46,242 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1771] 2023-02-27 03:22:46,242 >> loading file tokenizer_config.json\n",
            "[INFO|configuration_utils.py:651] 2023-02-27 03:22:46,242 >> loading configuration file /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training/config.json\n",
            "[INFO|configuration_utils.py:705] 2023-02-27 03:22:46,244 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"/root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function _get_tokenized_and_preprocessed_raw_datasets.<locals>.preprocess_function at 0x7eff443afee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on dataset #0:   0% 0/2 [00:00<?, ?ba/s]\n",
            "Running tokenizer on dataset #1:   0% 0/2 [00:00<?, ?ba/s]\u001b[A\n",
            "\n",
            "Running tokenizer on dataset #2:   0% 0/2 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #3:   0% 0/2 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #4:   0% 0/2 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #0:  50% 1/2 [00:01<00:01,  1.07s/ba]\n",
            "Running tokenizer on dataset #1:  50% 1/2 [00:01<00:01,  1.09s/ba]\u001b[A\n",
            "\n",
            "Running tokenizer on dataset #2:  50% 1/2 [00:01<00:01,  1.16s/ba]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #4:  50% 1/2 [00:01<00:01,  1.13s/ba]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #0: 100% 2/2 [00:01<00:00,  1.34ba/s]\n",
            "\n",
            "Running tokenizer on dataset #1: 100% 2/2 [00:01<00:00,  1.30ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #5:  50% 1/2 [00:01<00:01,  1.28s/ba]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Running tokenizer on dataset #2: 100% 2/2 [00:01<00:00,  1.23ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #4: 100% 2/2 [00:01<00:00,  1.34ba/s]\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #3: 100% 2/2 [00:01<00:00,  1.30ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #5: 100% 2/2 [00:01<00:00,  1.35ba/s]\n",
            "Running tokenizer on dataset #0:   0% 0/1 [00:00<?, ?ba/s]\n",
            "Running tokenizer on dataset #1:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\n",
            "\n",
            "Running tokenizer on dataset #2:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #0: 100% 1/1 [00:00<00:00,  4.17ba/s]\n",
            "\n",
            "Running tokenizer on dataset #1: 100% 1/1 [00:00<00:00,  3.64ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #4:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Running tokenizer on dataset #2: 100% 1/1 [00:00<00:00,  4.07ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #5:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #3: 100% 1/1 [00:00<00:00,  4.25ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #4: 100% 1/1 [00:00<00:00,  7.75ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Running tokenizer on dataset #5: 100% 1/1 [00:00<00:00,  8.76ba/s]\n",
            "2023-02-27 03:22:49 sparseml.transformers.text_classification INFO     Sample 6873 of training set: {'Unnamed: 0': 6873, 'text': 'feels like the grittiest movie that was ever made for the lifetime cable television network .', 'label': 0, 'input_ids': [101, 5683, 2066, 1996, 24842, 7368, 2102, 3185, 2008, 2001, 2412, 2081, 2005, 1996, 6480, 5830, 2547, 2897, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "INFO:sparseml.transformers.text_classification:Sample 6873 of training set: {'Unnamed: 0': 6873, 'text': 'feels like the grittiest movie that was ever made for the lifetime cable television network .', 'label': 0, 'input_ids': [101, 5683, 2066, 1996, 24842, 7368, 2102, 3185, 2008, 2001, 2412, 2081, 2005, 1996, 6480, 5830, 2547, 2897, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "2023-02-27 03:22:49 sparseml.transformers.text_classification INFO     Sample 3611 of training set: {'Unnamed: 0': 3611, 'text': \"like mike isn't going to make box office money that makes michael jordan jealous , but it has some cute moments , funny scenes , and hits the target audience ( young bow wow fans ) - with nothing but net .\", 'label': 1, 'input_ids': [101, 2066, 3505, 3475, 1005, 1056, 2183, 2000, 2191, 3482, 2436, 2769, 2008, 3084, 2745, 5207, 9981, 1010, 2021, 2009, 2038, 2070, 10140, 5312, 1010, 6057, 5019, 1010, 1998, 4978, 1996, 4539, 4378, 1006, 2402, 6812, 10166, 4599, 1007, 1011, 2007, 2498, 2021, 5658, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "INFO:sparseml.transformers.text_classification:Sample 3611 of training set: {'Unnamed: 0': 3611, 'text': \"like mike isn't going to make box office money that makes michael jordan jealous , but it has some cute moments , funny scenes , and hits the target audience ( young bow wow fans ) - with nothing but net .\", 'label': 1, 'input_ids': [101, 2066, 3505, 3475, 1005, 1056, 2183, 2000, 2191, 3482, 2436, 2769, 2008, 3084, 2745, 5207, 9981, 1010, 2021, 2009, 2038, 2070, 10140, 5312, 1010, 6057, 5019, 1010, 1998, 4978, 1996, 4539, 4378, 1006, 2402, 6812, 10166, 4599, 1007, 1011, 2007, 2498, 2021, 5658, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "2023-02-27 03:22:49 sparseml.transformers.text_classification INFO     Sample 7359 of training set: {'Unnamed: 0': 7359, 'text': \"eastwood winces , clutches his chest and gasps for breath . it's a spectacular performance - ahem , we hope it's only acting .\", 'label': 0, 'input_ids': [101, 24201, 29585, 2015, 1010, 29497, 2010, 3108, 1998, 23813, 2005, 3052, 1012, 2009, 1005, 1055, 1037, 12656, 2836, 1011, 6289, 6633, 1010, 2057, 3246, 2009, 1005, 1055, 2069, 3772, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "INFO:sparseml.transformers.text_classification:Sample 7359 of training set: {'Unnamed: 0': 7359, 'text': \"eastwood winces , clutches his chest and gasps for breath . it's a spectacular performance - ahem , we hope it's only acting .\", 'label': 0, 'input_ids': [101, 24201, 29585, 2015, 1010, 29497, 2010, 3108, 1998, 23813, 2005, 3052, 1012, 2009, 1005, 1055, 1037, 12656, 2836, 1011, 6289, 6633, 1010, 2057, 3246, 2009, 1005, 1055, 2069, 3772, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "2023-02-27 03:22:51 sparseml.transformers.sparsification.trainer INFO     Loaded SparseML recipe variable into manager for recipe: zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none, recipe_variables: None and metadata {'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'fp16': True}\n",
            "INFO:sparseml.transformers.sparsification.trainer:Loaded SparseML recipe variable into manager for recipe: zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none, recipe_variables: None and metadata {'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'fp16': True}\n",
            "2023-02-27 03:22:51 sparseml.transformers.sparsification.trainer WARNING  Overriding num_train_epochs from Recipe to 13\n",
            "WARNING:sparseml.transformers.sparsification.trainer:Overriding num_train_epochs from Recipe to 13\n",
            "[INFO|trainer.py:557] 2023-02-27 03:22:54,388 >> Using cuda_amp half precision backend\n",
            "2023-02-27 03:22:54 sparseml.transformers.sparsification.trainer INFO     Applied structure from SparseML recipe argument to model at epoch 0.0\n",
            "INFO:sparseml.transformers.sparsification.trainer:Applied structure from SparseML recipe argument to model at epoch 0.0\n",
            "2023-02-27 03:22:54 sparseml.transformers.sparsification.trainer INFO     Reloaded model state after SparseML recipe structure modifications from /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training\n",
            "INFO:sparseml.transformers.sparsification.trainer:Reloaded model state after SparseML recipe structure modifications from /root/.cache/sparsezoo/d9914a7a-fdc4-459c-9268-d6e7aa1833b8/training\n",
            "[INFO|trainer.py:725] 2023-02-27 03:22:54,395 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "2023-02-27 03:22:54 sparseml.pytorch.sparsification.distillation.modifier_distillation_base WARNING  distillation_teacher set to disable, disabling distillation modifier\n",
            "WARNING:sparseml.pytorch.sparsification.distillation.modifier_distillation_base:distillation_teacher set to disable, disabling distillation modifier\n",
            "2023-02-27 03:22:54 sparseml.transformers.sparsification.trainer INFO     Modified the scaler from the recipe for training with total_batch_size: 32 and steps_per_epoch: 267\n",
            "INFO:sparseml.transformers.sparsification.trainer:Modified the scaler from the recipe for training with total_batch_size: 32 and steps_per_epoch: 267\n",
            "2023-02-27 03:22:54 sparseml.transformers.sparsification.trainer WARNING  Overrode the lr_scheduler from SparseML recipe\n",
            "WARNING:sparseml.transformers.sparsification.trainer:Overrode the lr_scheduler from SparseML recipe\n",
            "[INFO|trainer.py:1607] 2023-02-27 03:22:54,413 >> ***** Running training *****\n",
            "[INFO|trainer.py:1608] 2023-02-27 03:22:54,413 >>   Num examples = 8530\n",
            "[INFO|trainer.py:1609] 2023-02-27 03:22:54,413 >>   Num Epochs = 13\n",
            "[INFO|trainer.py:1610] 2023-02-27 03:22:54,413 >>   Instantaneous batch size per device = 32\n",
            "[INFO|trainer.py:1611] 2023-02-27 03:22:54,413 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1612] 2023-02-27 03:22:54,413 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1613] 2023-02-27 03:22:54,413 >>   Total optimization steps = 3471\n",
            "  8% 267/3471 [01:18<14:29,  3.68it/s][INFO|trainer.py:725] 2023-02-27 03:24:12,702 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2916] 2023-02-27 03:24:12,706 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2918] 2023-02-27 03:24:12,707 >>   Num examples = 1066\n",
            "[INFO|trainer.py:2921] 2023-02-27 03:24:12,707 >>   Batch size = 32\n",
            "\n",
            "  0% 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 2/34 [00:00<00:03,  8.95it/s]\u001b[A\n",
            "  9% 3/34 [00:00<00:04,  6.36it/s]\u001b[A\n",
            " 12% 4/34 [00:00<00:05,  5.58it/s]\u001b[A\n",
            " 15% 5/34 [00:00<00:05,  5.24it/s]\u001b[A\n",
            " 18% 6/34 [00:01<00:05,  5.05it/s]\u001b[A\n",
            " 21% 7/34 [00:01<00:05,  4.94it/s]\u001b[A\n",
            " 24% 8/34 [00:01<00:05,  4.84it/s]\u001b[A\n",
            " 26% 9/34 [00:01<00:05,  4.78it/s]\u001b[A\n",
            " 29% 10/34 [00:01<00:05,  4.74it/s]\u001b[A\n",
            " 32% 11/34 [00:02<00:04,  4.72it/s]\u001b[A\n",
            " 35% 12/34 [00:02<00:04,  4.70it/s]\u001b[A\n",
            " 38% 13/34 [00:02<00:04,  4.69it/s]\u001b[A\n",
            " 41% 14/34 [00:02<00:04,  4.67it/s]\u001b[A\n",
            " 44% 15/34 [00:03<00:04,  4.64it/s]\u001b[A\n",
            " 47% 16/34 [00:03<00:03,  4.66it/s]\u001b[A\n",
            " 50% 17/34 [00:03<00:03,  4.64it/s]\u001b[A\n",
            " 53% 18/34 [00:03<00:03,  4.66it/s]\u001b[A\n",
            " 56% 19/34 [00:03<00:03,  4.65it/s]\u001b[A\n",
            " 59% 20/34 [00:04<00:03,  4.66it/s]\u001b[A\n",
            " 62% 21/34 [00:04<00:02,  4.68it/s]\u001b[A\n",
            " 65% 22/34 [00:04<00:02,  4.69it/s]\u001b[A\n",
            " 68% 23/34 [00:04<00:02,  4.69it/s]\u001b[A\n",
            " 71% 24/34 [00:04<00:02,  4.68it/s]\u001b[A\n",
            " 74% 25/34 [00:05<00:01,  4.69it/s]\u001b[A\n",
            " 76% 26/34 [00:05<00:01,  4.69it/s]\u001b[A\n",
            " 79% 27/34 [00:05<00:01,  4.70it/s]\u001b[A\n",
            " 82% 28/34 [00:05<00:01,  4.69it/s]\u001b[A\n",
            " 85% 29/34 [00:06<00:01,  4.69it/s]\u001b[A\n",
            " 88% 30/34 [00:06<00:00,  4.70it/s]\u001b[A\n",
            " 91% 31/34 [00:06<00:00,  4.71it/s]\u001b[A\n",
            " 94% 32/34 [00:06<00:00,  4.71it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.38472527265548706, 'eval_accuracy': 0.8255159258842468, 'eval_runtime': 7.1587, 'eval_samples_per_second': 148.91, 'eval_steps_per_second': 4.749, 'epoch': 1.0}\n",
            "  8% 267/3471 [01:25<14:29,  3.68it/s]\n",
            "100% 34/34 [00:06<00:00,  4.70it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2665] 2023-02-27 03:24:19,866 >> Saving model checkpoint to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267\n",
            "[INFO|configuration_utils.py:447] 2023-02-27 03:24:19,868 >> Configuration saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/config.json\n",
            "[INFO|modeling_utils.py:1624] 2023-02-27 03:24:21,259 >> Model weights saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2023-02-27 03:24:21,260 >> tokenizer config file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2023-02-27 03:24:21,260 >> Special tokens file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/special_tokens_map.json\n",
            "2023-02-27 03:24:21 sparseml.transformers.sparsification.trainer INFO     Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/recipe.yaml\n",
            "INFO:sparseml.transformers.sparsification.trainer:Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267/recipe.yaml\n",
            "{'loss': 0.3867, 'learning_rate': 0.00012843560933448574, 'epoch': 1.87}\n",
            " 15% 534/3471 [02:47<12:48,  3.82it/s][INFO|trainer.py:725] 2023-02-27 03:25:42,366 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2916] 2023-02-27 03:25:42,371 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2918] 2023-02-27 03:25:42,372 >>   Num examples = 1066\n",
            "[INFO|trainer.py:2921] 2023-02-27 03:25:42,372 >>   Batch size = 32\n",
            "\n",
            "  0% 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 2/34 [00:00<00:03,  9.22it/s]\u001b[A\n",
            "  9% 3/34 [00:00<00:04,  6.53it/s]\u001b[A\n",
            " 12% 4/34 [00:00<00:05,  5.62it/s]\u001b[A\n",
            " 15% 5/34 [00:00<00:05,  5.22it/s]\u001b[A\n",
            " 18% 6/34 [00:01<00:05,  5.02it/s]\u001b[A\n",
            " 21% 7/34 [00:01<00:05,  4.89it/s]\u001b[A\n",
            " 24% 8/34 [00:01<00:05,  4.80it/s]\u001b[A\n",
            " 26% 9/34 [00:01<00:05,  4.69it/s]\u001b[A\n",
            " 29% 10/34 [00:01<00:05,  4.67it/s]\u001b[A\n",
            " 32% 11/34 [00:02<00:04,  4.66it/s]\u001b[A\n",
            " 35% 12/34 [00:02<00:04,  4.65it/s]\u001b[A\n",
            " 38% 13/34 [00:02<00:04,  4.64it/s]\u001b[A\n",
            " 41% 14/34 [00:02<00:04,  4.63it/s]\u001b[A\n",
            " 44% 15/34 [00:03<00:04,  4.63it/s]\u001b[A\n",
            " 47% 16/34 [00:03<00:03,  4.63it/s]\u001b[A\n",
            " 50% 17/34 [00:03<00:03,  4.64it/s]\u001b[A\n",
            " 53% 18/34 [00:03<00:03,  4.63it/s]\u001b[A\n",
            " 56% 19/34 [00:03<00:03,  4.62it/s]\u001b[A\n",
            " 59% 20/34 [00:04<00:03,  4.62it/s]\u001b[A\n",
            " 62% 21/34 [00:04<00:02,  4.59it/s]\u001b[A\n",
            " 65% 22/34 [00:04<00:02,  4.60it/s]\u001b[A\n",
            " 68% 23/34 [00:04<00:02,  4.60it/s]\u001b[A\n",
            " 71% 24/34 [00:05<00:02,  4.50it/s]\u001b[A\n",
            " 74% 25/34 [00:05<00:01,  4.54it/s]\u001b[A\n",
            " 76% 26/34 [00:05<00:01,  4.56it/s]\u001b[A\n",
            " 79% 27/34 [00:05<00:01,  4.56it/s]\u001b[A\n",
            " 82% 28/34 [00:05<00:01,  4.58it/s]\u001b[A\n",
            " 85% 29/34 [00:06<00:01,  4.60it/s]\u001b[A\n",
            " 88% 30/34 [00:06<00:00,  4.63it/s]\u001b[A\n",
            " 91% 31/34 [00:06<00:00,  4.60it/s]\u001b[A\n",
            " 94% 32/34 [00:06<00:00,  4.63it/s]\u001b[A\n",
            " 97% 33/34 [00:06<00:00,  4.65it/s]\u001b[A\n",
            "{'eval_loss': 0.40558791160583496, 'eval_accuracy': 0.8377110958099365, 'eval_runtime': 7.2511, 'eval_samples_per_second': 147.011, 'eval_steps_per_second': 4.689, 'epoch': 2.0}\n",
            "\n",
            " 15% 534/3471 [02:55<12:48,  3.82it/s]\n",
            "                                   \u001b[A[INFO|trainer.py:2665] 2023-02-27 03:25:49,624 >> Saving model checkpoint to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534\n",
            "[INFO|configuration_utils.py:447] 2023-02-27 03:25:49,625 >> Configuration saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/config.json\n",
            "[INFO|modeling_utils.py:1624] 2023-02-27 03:25:50,960 >> Model weights saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2023-02-27 03:25:50,960 >> tokenizer config file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2023-02-27 03:25:50,961 >> Special tokens file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/special_tokens_map.json\n",
            "2023-02-27 03:25:51 sparseml.transformers.sparsification.trainer INFO     Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/recipe.yaml\n",
            "INFO:sparseml.transformers.sparsification.trainer:Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534/recipe.yaml\n",
            "[INFO|trainer.py:2743] 2023-02-27 03:25:54,457 >> Deleting older checkpoint [sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-267] due to args.save_total_limit\n",
            " 23% 801/3471 [04:17<12:05,  3.68it/s][INFO|trainer.py:725] 2023-02-27 03:27:12,276 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2916] 2023-02-27 03:27:12,281 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2918] 2023-02-27 03:27:12,281 >>   Num examples = 1066\n",
            "[INFO|trainer.py:2921] 2023-02-27 03:27:12,281 >>   Batch size = 32\n",
            "\n",
            "  0% 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 2/34 [00:00<00:03,  9.43it/s]\u001b[A\n",
            "  9% 3/34 [00:00<00:04,  6.71it/s]\u001b[A\n",
            " 12% 4/34 [00:00<00:05,  5.77it/s]\u001b[A\n",
            " 15% 5/34 [00:00<00:05,  5.34it/s]\u001b[A\n",
            " 18% 6/34 [00:01<00:05,  5.12it/s]\u001b[A\n",
            " 21% 7/34 [00:01<00:05,  5.01it/s]\u001b[A\n",
            " 24% 8/34 [00:01<00:05,  4.93it/s]\u001b[A\n",
            " 26% 9/34 [00:01<00:05,  4.84it/s]\u001b[A\n",
            " 29% 10/34 [00:01<00:04,  4.80it/s]\u001b[A\n",
            " 32% 11/34 [00:02<00:04,  4.78it/s]\u001b[A\n",
            " 35% 12/34 [00:02<00:04,  4.78it/s]\u001b[A\n",
            " 38% 13/34 [00:02<00:04,  4.75it/s]\u001b[A\n",
            " 41% 14/34 [00:02<00:04,  4.73it/s]\u001b[A\n",
            " 44% 15/34 [00:02<00:04,  4.72it/s]\u001b[A\n",
            " 47% 16/34 [00:03<00:03,  4.74it/s]\u001b[A\n",
            " 50% 17/34 [00:03<00:03,  4.73it/s]\u001b[A\n",
            " 53% 18/34 [00:03<00:03,  4.74it/s]\u001b[A\n",
            " 56% 19/34 [00:03<00:03,  4.73it/s]\u001b[A\n",
            " 59% 20/34 [00:04<00:02,  4.72it/s]\u001b[A\n",
            " 62% 21/34 [00:04<00:02,  4.72it/s]\u001b[A\n",
            " 65% 22/34 [00:04<00:02,  4.73it/s]\u001b[A\n",
            " 68% 23/34 [00:04<00:02,  4.71it/s]\u001b[A\n",
            " 71% 24/34 [00:04<00:02,  4.70it/s]\u001b[A\n",
            " 74% 25/34 [00:05<00:01,  4.70it/s]\u001b[A\n",
            " 76% 26/34 [00:05<00:01,  4.72it/s]\u001b[A\n",
            " 79% 27/34 [00:05<00:01,  4.72it/s]\u001b[A\n",
            " 82% 28/34 [00:05<00:01,  4.73it/s]\u001b[A\n",
            " 85% 29/34 [00:05<00:01,  4.71it/s]\u001b[A\n",
            " 88% 30/34 [00:06<00:00,  4.73it/s]\u001b[A\n",
            " 91% 31/34 [00:06<00:00,  4.72it/s]\u001b[A\n",
            " 94% 32/34 [00:06<00:00,  4.73it/s]\u001b[A\n",
            " 97% 33/34 [00:06<00:00,  4.71it/s]\u001b[A\n",
            "{'eval_loss': 0.4870096445083618, 'eval_accuracy': 0.8339587450027466, 'eval_runtime': 7.0697, 'eval_samples_per_second': 150.784, 'eval_steps_per_second': 4.809, 'epoch': 3.0}\n",
            "\n",
            " 23% 801/3471 [04:24<12:05,  3.68it/s]\n",
            "                                   \u001b[A[INFO|trainer.py:2665] 2023-02-27 03:27:19,352 >> Saving model checkpoint to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801\n",
            "[INFO|configuration_utils.py:447] 2023-02-27 03:27:19,353 >> Configuration saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/config.json\n",
            "[INFO|modeling_utils.py:1624] 2023-02-27 03:27:20,698 >> Model weights saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2023-02-27 03:27:20,699 >> tokenizer config file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2023-02-27 03:27:20,699 >> Special tokens file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/special_tokens_map.json\n",
            "2023-02-27 03:27:20 sparseml.transformers.sparsification.trainer INFO     Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/recipe.yaml\n",
            "INFO:sparseml.transformers.sparsification.trainer:Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801/recipe.yaml\n",
            "[INFO|trainer.py:2743] 2023-02-27 03:27:24,169 >> Deleting older checkpoint [sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-534] due to args.save_total_limit\n",
            "{'loss': 0.1398, 'learning_rate': 0.00010682800345721694, 'epoch': 3.75}\n",
            " 31% 1068/3471 [05:47<10:29,  3.82it/s][INFO|trainer.py:725] 2023-02-27 03:28:42,106 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2916] 2023-02-27 03:28:42,109 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2918] 2023-02-27 03:28:42,109 >>   Num examples = 1066\n",
            "[INFO|trainer.py:2921] 2023-02-27 03:28:42,109 >>   Batch size = 32\n",
            "\n",
            "  0% 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 2/34 [00:00<00:03,  9.09it/s]\u001b[A\n",
            "  9% 3/34 [00:00<00:04,  6.44it/s]\u001b[A\n",
            " 12% 4/34 [00:00<00:05,  5.42it/s]\u001b[A\n",
            " 15% 5/34 [00:00<00:06,  4.47it/s]\u001b[A\n",
            " 18% 6/34 [00:01<00:06,  4.54it/s]\u001b[A\n",
            " 21% 7/34 [00:01<00:05,  4.57it/s]\u001b[A\n",
            " 24% 8/34 [00:01<00:05,  4.56it/s]\u001b[A\n",
            " 26% 9/34 [00:01<00:05,  4.53it/s]\u001b[A\n",
            " 29% 10/34 [00:02<00:05,  4.40it/s]\u001b[A\n",
            " 32% 11/34 [00:02<00:05,  4.28it/s]\u001b[A\n",
            " 35% 12/34 [00:02<00:05,  4.38it/s]\u001b[A\n",
            " 38% 13/34 [00:02<00:04,  4.45it/s]\u001b[A\n",
            " 41% 14/34 [00:02<00:04,  4.51it/s]\u001b[A\n",
            " 44% 15/34 [00:03<00:04,  4.51it/s]\u001b[A\n",
            " 47% 16/34 [00:03<00:04,  4.47it/s]\u001b[A\n",
            " 50% 17/34 [00:03<00:03,  4.50it/s]\u001b[A\n",
            " 53% 18/34 [00:03<00:03,  4.54it/s]\u001b[A\n",
            " 56% 19/34 [00:04<00:03,  4.57it/s]\u001b[A\n",
            " 59% 20/34 [00:04<00:03,  4.52it/s]\u001b[A\n",
            " 62% 21/34 [00:04<00:02,  4.36it/s]\u001b[A\n",
            " 65% 22/34 [00:04<00:02,  4.43it/s]\u001b[A\n",
            " 68% 23/34 [00:05<00:02,  4.30it/s]\u001b[A\n",
            " 71% 24/34 [00:05<00:02,  4.38it/s]\u001b[A\n",
            " 74% 25/34 [00:05<00:02,  4.36it/s]\u001b[A\n",
            " 76% 26/34 [00:05<00:01,  4.31it/s]\u001b[A\n",
            " 79% 27/34 [00:05<00:01,  4.40it/s]\u001b[A\n",
            " 82% 28/34 [00:06<00:01,  4.42it/s]\u001b[A\n",
            " 85% 29/34 [00:06<00:01,  4.51it/s]\u001b[A\n",
            " 88% 30/34 [00:06<00:00,  4.54it/s]\u001b[A\n",
            " 91% 31/34 [00:06<00:00,  4.60it/s]\u001b[A\n",
            " 94% 32/34 [00:07<00:00,  4.61it/s]\u001b[A\n",
            " 97% 33/34 [00:07<00:00,  4.64it/s]\u001b[A\n",
            "{'eval_loss': 0.6531708836555481, 'eval_accuracy': 0.8433395624160767, 'eval_runtime': 7.5077, 'eval_samples_per_second': 141.988, 'eval_steps_per_second': 4.529, 'epoch': 4.0}\n",
            "\n",
            " 31% 1068/3471 [05:55<10:29,  3.82it/s]\n",
            "                                   \u001b[A[INFO|trainer.py:2665] 2023-02-27 03:28:49,618 >> Saving model checkpoint to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068\n",
            "[INFO|configuration_utils.py:447] 2023-02-27 03:28:49,619 >> Configuration saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/config.json\n",
            "[INFO|modeling_utils.py:1624] 2023-02-27 03:28:50,944 >> Model weights saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2023-02-27 03:28:50,945 >> tokenizer config file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2023-02-27 03:28:50,945 >> Special tokens file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/special_tokens_map.json\n",
            "2023-02-27 03:28:50 sparseml.transformers.sparsification.trainer INFO     Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/recipe.yaml\n",
            "INFO:sparseml.transformers.sparsification.trainer:Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068/recipe.yaml\n",
            "[INFO|trainer.py:2743] 2023-02-27 03:28:54,442 >> Deleting older checkpoint [sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-801] due to args.save_total_limit\n",
            " 38% 1335/3471 [07:17<09:10,  3.88it/s][INFO|trainer.py:725] 2023-02-27 03:30:12,189 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2916] 2023-02-27 03:30:12,193 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2918] 2023-02-27 03:30:12,193 >>   Num examples = 1066\n",
            "[INFO|trainer.py:2921] 2023-02-27 03:30:12,193 >>   Batch size = 32\n",
            "\n",
            "  0% 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 2/34 [00:00<00:03,  9.46it/s]\u001b[A\n",
            "  9% 3/34 [00:00<00:04,  6.67it/s]\u001b[A\n",
            " 12% 4/34 [00:00<00:05,  5.76it/s]\u001b[A\n",
            " 15% 5/34 [00:00<00:05,  5.34it/s]\u001b[A\n",
            " 18% 6/34 [00:01<00:05,  5.14it/s]\u001b[A\n",
            " 21% 7/34 [00:01<00:05,  5.02it/s]\u001b[A\n",
            " 24% 8/34 [00:01<00:05,  4.91it/s]\u001b[A\n",
            " 26% 9/34 [00:01<00:05,  4.84it/s]\u001b[A\n",
            " 29% 10/34 [00:01<00:05,  4.79it/s]\u001b[A\n",
            " 32% 11/34 [00:02<00:04,  4.77it/s]\u001b[A\n",
            " 35% 12/34 [00:02<00:04,  4.76it/s]\u001b[A\n",
            " 38% 13/34 [00:02<00:04,  4.75it/s]\u001b[A\n",
            " 41% 14/34 [00:02<00:04,  4.73it/s]\u001b[A\n",
            " 44% 15/34 [00:02<00:04,  4.73it/s]\u001b[A\n",
            " 47% 16/34 [00:03<00:03,  4.72it/s]\u001b[A\n",
            " 50% 17/34 [00:03<00:03,  4.73it/s]\u001b[A\n",
            " 53% 18/34 [00:03<00:03,  4.72it/s]\u001b[A\n",
            " 56% 19/34 [00:03<00:03,  4.70it/s]\u001b[A\n",
            " 59% 20/34 [00:04<00:02,  4.71it/s]\u001b[A\n",
            " 62% 21/34 [00:04<00:02,  4.70it/s]\u001b[A\n",
            " 65% 22/34 [00:04<00:02,  4.71it/s]\u001b[A\n",
            " 68% 23/34 [00:04<00:02,  4.71it/s]\u001b[A\n",
            " 71% 24/34 [00:04<00:02,  4.71it/s]\u001b[A\n",
            " 74% 25/34 [00:05<00:01,  4.72it/s]\u001b[A\n",
            " 76% 26/34 [00:05<00:01,  4.71it/s]\u001b[A\n",
            " 79% 27/34 [00:05<00:01,  4.72it/s]\u001b[A\n",
            " 82% 28/34 [00:05<00:01,  4.70it/s]\u001b[A\n",
            " 85% 29/34 [00:05<00:01,  4.72it/s]\u001b[A\n",
            " 88% 30/34 [00:06<00:00,  4.71it/s]\u001b[A\n",
            " 91% 31/34 [00:06<00:00,  4.68it/s]\u001b[A\n",
            " 94% 32/34 [00:06<00:00,  4.68it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.8776453733444214, 'eval_accuracy': 0.8424015045166016, 'eval_runtime': 7.0902, 'eval_samples_per_second': 150.348, 'eval_steps_per_second': 4.795, 'epoch': 5.0}\n",
            " 38% 1335/3471 [07:24<09:10,  3.88it/s]\n",
            "100% 34/34 [00:06<00:00,  4.66it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2665] 2023-02-27 03:30:19,285 >> Saving model checkpoint to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335\n",
            "[INFO|configuration_utils.py:447] 2023-02-27 03:30:19,286 >> Configuration saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/config.json\n",
            "[INFO|modeling_utils.py:1624] 2023-02-27 03:30:20,592 >> Model weights saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2023-02-27 03:30:20,593 >> tokenizer config file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2023-02-27 03:30:20,593 >> Special tokens file saved in sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/special_tokens_map.json\n",
            "2023-02-27 03:30:20 sparseml.transformers.sparsification.trainer INFO     Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/recipe.yaml\n",
            "INFO:sparseml.transformers.sparsification.trainer:Saved SparseML recipe with model state to sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1335/recipe.yaml\n",
            "[INFO|trainer.py:2743] 2023-02-27 03:30:24,159 >> Deleting older checkpoint [sparse_quantized_bert-text_classification_rotten_tomatoes-local_dataset/checkpoint-1068] due to args.save_total_limit\n",
            " 39% 1369/3471 [07:39<09:48,  3.57it/s]"
          ]
        }
      ]
    }
  ]
}