modifiers:
  - !QuantizationModifier
    ignore: ["lm_head", "Embedding", "OPTLearnedPositionalEmbedding", "QuantizableBatchMatMul", "BMMOutput_QK", "BMMOutput_PV", "ReLU", "LayerNorm"]
    scheme_overrides:
      BMMLeftInput_QK:
        input_activations:
          num_bits: 8
          symmetric: True
        output_activations: null
      BMMRightInput_QK:
        input_activations:
          num_bits: 8
          symmetric: False
        output_activations: null
      BMMLeftInput_PV:
        input_activations:
          num_bits: 8
          symmetric: False
        output_activations: null
      BMMRightInput_PV:
        input_activations:
          num_bits: 8
          symmetric: True
        output_activations: null
  - !SparseOPTModifier
    sparsity: 0.5
    block_size: 128
    quantize: True